{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all modules needed\n",
    "import models.eda as eda\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, Normalizer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "from sklearn.utils import resample\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from skopt import gp_minimize\n",
    "from skopt.space import Real, Integer\n",
    "from skopt.utils import use_named_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s5/ccqphxw12ql_3b8zcycpgnym0000gn/T/ipykernel_12710/1235657692.py:3: DtypeWarning: Columns (4) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  invoice = eda.load_data(\"data/train/invoice_train.csv\")\n"
     ]
    }
   ],
   "source": [
    "# df_client and df_invoice are being loaded from the data folder\n",
    "client = eda.load_data(\"data/train/client_train.csv\")\n",
    "invoice = eda.load_data(\"data/train/invoice_train.csv\")\n",
    "df = eda.feature_change(client, invoice)\n",
    "df = eda.get_mean_consumption(df)\n",
    "df = eda.get_historical_mean(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>district</th>\n",
       "      <th>client_id</th>\n",
       "      <th>client_catg</th>\n",
       "      <th>region</th>\n",
       "      <th>creation_date</th>\n",
       "      <th>target</th>\n",
       "      <th>region_group</th>\n",
       "      <th>coop_time</th>\n",
       "      <th>invoice_date</th>\n",
       "      <th>tarif_type</th>\n",
       "      <th>...</th>\n",
       "      <th>reading_remarque</th>\n",
       "      <th>counter_coefficient</th>\n",
       "      <th>months_number</th>\n",
       "      <th>counter_type</th>\n",
       "      <th>invoice_month</th>\n",
       "      <th>invoice_year</th>\n",
       "      <th>is_weekday</th>\n",
       "      <th>total_consumption</th>\n",
       "      <th>mean_consumption_per_year</th>\n",
       "      <th>historical_mean_consumption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>101</td>\n",
       "      <td>1994-12-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>200</td>\n",
       "      <td>288</td>\n",
       "      <td>2005-10-17</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>2005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>124</td>\n",
       "      <td>124.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>101</td>\n",
       "      <td>1994-12-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>200</td>\n",
       "      <td>288</td>\n",
       "      <td>2006-10-18</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>2006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>159</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>124.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>101</td>\n",
       "      <td>1994-12-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>200</td>\n",
       "      <td>288</td>\n",
       "      <td>2006-06-23</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>141.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>101</td>\n",
       "      <td>1994-12-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>200</td>\n",
       "      <td>288</td>\n",
       "      <td>2006-02-24</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>141</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>148.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>101</td>\n",
       "      <td>1994-12-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>200</td>\n",
       "      <td>288</td>\n",
       "      <td>2007-02-26</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2007</td>\n",
       "      <td>0.0</td>\n",
       "      <td>182</td>\n",
       "      <td>232.666667</td>\n",
       "      <td>146.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>101</td>\n",
       "      <td>1994-12-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>200</td>\n",
       "      <td>288</td>\n",
       "      <td>2007-10-25</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>2007</td>\n",
       "      <td>0.0</td>\n",
       "      <td>276</td>\n",
       "      <td>232.666667</td>\n",
       "      <td>153.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>101</td>\n",
       "      <td>1994-12-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>200</td>\n",
       "      <td>288</td>\n",
       "      <td>2007-06-27</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2007</td>\n",
       "      <td>0.0</td>\n",
       "      <td>240</td>\n",
       "      <td>232.666667</td>\n",
       "      <td>174.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>101</td>\n",
       "      <td>1994-12-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>200</td>\n",
       "      <td>288</td>\n",
       "      <td>2008-01-04</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2008</td>\n",
       "      <td>0.0</td>\n",
       "      <td>277</td>\n",
       "      <td>207.333333</td>\n",
       "      <td>183.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>101</td>\n",
       "      <td>1994-12-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>200</td>\n",
       "      <td>288</td>\n",
       "      <td>2008-07-28</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2008</td>\n",
       "      <td>0.0</td>\n",
       "      <td>171</td>\n",
       "      <td>207.333333</td>\n",
       "      <td>195.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>101</td>\n",
       "      <td>1994-12-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>200</td>\n",
       "      <td>288</td>\n",
       "      <td>2008-11-25</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>2008</td>\n",
       "      <td>0.0</td>\n",
       "      <td>174</td>\n",
       "      <td>207.333333</td>\n",
       "      <td>192.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>101</td>\n",
       "      <td>1994-12-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>200</td>\n",
       "      <td>288</td>\n",
       "      <td>2009-11-24</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>2009</td>\n",
       "      <td>0.0</td>\n",
       "      <td>267</td>\n",
       "      <td>298.000000</td>\n",
       "      <td>190.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>101</td>\n",
       "      <td>1994-12-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>200</td>\n",
       "      <td>288</td>\n",
       "      <td>2009-07-27</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2009</td>\n",
       "      <td>0.0</td>\n",
       "      <td>312</td>\n",
       "      <td>298.000000</td>\n",
       "      <td>197.545455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>101</td>\n",
       "      <td>1994-12-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>200</td>\n",
       "      <td>288</td>\n",
       "      <td>2009-01-04</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2009</td>\n",
       "      <td>1.0</td>\n",
       "      <td>315</td>\n",
       "      <td>298.000000</td>\n",
       "      <td>207.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>101</td>\n",
       "      <td>1994-12-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>200</td>\n",
       "      <td>288</td>\n",
       "      <td>2010-07-22</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>278</td>\n",
       "      <td>262.666667</td>\n",
       "      <td>215.384615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>101</td>\n",
       "      <td>1994-12-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>200</td>\n",
       "      <td>288</td>\n",
       "      <td>2010-03-29</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>276</td>\n",
       "      <td>262.666667</td>\n",
       "      <td>219.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>101</td>\n",
       "      <td>1994-12-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>200</td>\n",
       "      <td>288</td>\n",
       "      <td>2010-11-24</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>2010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>234</td>\n",
       "      <td>262.666667</td>\n",
       "      <td>223.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>101</td>\n",
       "      <td>1994-12-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>200</td>\n",
       "      <td>288</td>\n",
       "      <td>2011-11-22</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>2011</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1082</td>\n",
       "      <td>988.333333</td>\n",
       "      <td>224.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>101</td>\n",
       "      <td>1994-12-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>200</td>\n",
       "      <td>288</td>\n",
       "      <td>2011-07-22</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2011</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1386</td>\n",
       "      <td>988.333333</td>\n",
       "      <td>274.705882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>101</td>\n",
       "      <td>1994-12-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>200</td>\n",
       "      <td>288</td>\n",
       "      <td>2011-03-30</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2011</td>\n",
       "      <td>0.0</td>\n",
       "      <td>497</td>\n",
       "      <td>988.333333</td>\n",
       "      <td>336.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>101</td>\n",
       "      <td>1994-12-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>200</td>\n",
       "      <td>288</td>\n",
       "      <td>2012-03-27</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>292</td>\n",
       "      <td>602.000000</td>\n",
       "      <td>344.894737</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   district  client_id client_catg region creation_date  target  region_group  \\\n",
       "0        60          0          11    101    1994-12-31     0.0           200   \n",
       "1        60          0          11    101    1994-12-31     0.0           200   \n",
       "2        60          0          11    101    1994-12-31     0.0           200   \n",
       "3        60          0          11    101    1994-12-31     0.0           200   \n",
       "4        60          0          11    101    1994-12-31     0.0           200   \n",
       "5        60          0          11    101    1994-12-31     0.0           200   \n",
       "6        60          0          11    101    1994-12-31     0.0           200   \n",
       "7        60          0          11    101    1994-12-31     0.0           200   \n",
       "8        60          0          11    101    1994-12-31     0.0           200   \n",
       "9        60          0          11    101    1994-12-31     0.0           200   \n",
       "10       60          0          11    101    1994-12-31     0.0           200   \n",
       "11       60          0          11    101    1994-12-31     0.0           200   \n",
       "12       60          0          11    101    1994-12-31     0.0           200   \n",
       "13       60          0          11    101    1994-12-31     0.0           200   \n",
       "14       60          0          11    101    1994-12-31     0.0           200   \n",
       "15       60          0          11    101    1994-12-31     0.0           200   \n",
       "16       60          0          11    101    1994-12-31     0.0           200   \n",
       "17       60          0          11    101    1994-12-31     0.0           200   \n",
       "18       60          0          11    101    1994-12-31     0.0           200   \n",
       "19       60          0          11    101    1994-12-31     0.0           200   \n",
       "\n",
       "    coop_time invoice_date  tarif_type  ...  reading_remarque  \\\n",
       "0         288   2005-10-17          11  ...                 6   \n",
       "1         288   2006-10-18          11  ...                 6   \n",
       "2         288   2006-06-23          11  ...                 6   \n",
       "3         288   2006-02-24          11  ...                 6   \n",
       "4         288   2007-02-26          11  ...                 6   \n",
       "5         288   2007-10-25          11  ...                 6   \n",
       "6         288   2007-06-27          11  ...                 6   \n",
       "7         288   2008-01-04          11  ...                 6   \n",
       "8         288   2008-07-28          11  ...                 6   \n",
       "9         288   2008-11-25          11  ...                 6   \n",
       "10        288   2009-11-24          11  ...                 6   \n",
       "11        288   2009-07-27          11  ...                 6   \n",
       "12        288   2009-01-04          11  ...                 6   \n",
       "13        288   2010-07-22          11  ...                 6   \n",
       "14        288   2010-03-29          11  ...                 6   \n",
       "15        288   2010-11-24          11  ...                 6   \n",
       "16        288   2011-11-22          11  ...                 6   \n",
       "17        288   2011-07-22          11  ...                 9   \n",
       "18        288   2011-03-30          11  ...                 6   \n",
       "19        288   2012-03-27          11  ...                 8   \n",
       "\n",
       "    counter_coefficient  months_number  counter_type  invoice_month  \\\n",
       "0                     1              4             1             10   \n",
       "1                     1              4             1             10   \n",
       "2                     1              4             1              6   \n",
       "3                     1              4             1              2   \n",
       "4                     1              4             1              2   \n",
       "5                     1              4             1             10   \n",
       "6                     1              4             1              6   \n",
       "7                     1              4             1              1   \n",
       "8                     1              4             1              7   \n",
       "9                     1              4             1             11   \n",
       "10                    1              4             1             11   \n",
       "11                    1              4             1              7   \n",
       "12                    1              4             1              1   \n",
       "13                    1              4             1              7   \n",
       "14                    1              4             1              3   \n",
       "15                    1              4             1             11   \n",
       "16                    1              4             1             11   \n",
       "17                    1              4             1              7   \n",
       "18                    1              4             1              3   \n",
       "19                    1              4             1              3   \n",
       "\n",
       "    invoice_year  is_weekday  total_consumption  mean_consumption_per_year  \\\n",
       "0           2005         0.0                124                 124.000000   \n",
       "1           2006         0.0                159                 154.000000   \n",
       "2           2006         0.0                162                 154.000000   \n",
       "3           2006         0.0                141                 154.000000   \n",
       "4           2007         0.0                182                 232.666667   \n",
       "5           2007         0.0                276                 232.666667   \n",
       "6           2007         0.0                240                 232.666667   \n",
       "7           2008         0.0                277                 207.333333   \n",
       "8           2008         0.0                171                 207.333333   \n",
       "9           2008         0.0                174                 207.333333   \n",
       "10          2009         0.0                267                 298.000000   \n",
       "11          2009         0.0                312                 298.000000   \n",
       "12          2009         1.0                315                 298.000000   \n",
       "13          2010         0.0                278                 262.666667   \n",
       "14          2010         0.0                276                 262.666667   \n",
       "15          2010         0.0                234                 262.666667   \n",
       "16          2011         0.0               1082                 988.333333   \n",
       "17          2011         0.0               1386                 988.333333   \n",
       "18          2011         0.0                497                 988.333333   \n",
       "19          2012         0.0                292                 602.000000   \n",
       "\n",
       "    historical_mean_consumption  \n",
       "0                      0.000000  \n",
       "1                    124.000000  \n",
       "2                    141.500000  \n",
       "3                    148.333333  \n",
       "4                    146.500000  \n",
       "5                    153.600000  \n",
       "6                    174.000000  \n",
       "7                    183.428571  \n",
       "8                    195.125000  \n",
       "9                    192.444444  \n",
       "10                   190.600000  \n",
       "11                   197.545455  \n",
       "12                   207.083333  \n",
       "13                   215.384615  \n",
       "14                   219.857143  \n",
       "15                   223.600000  \n",
       "16                   224.250000  \n",
       "17                   274.705882  \n",
       "18                   336.444444  \n",
       "19                   344.894737  \n",
       "\n",
       "[20 rows x 23 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline model\n",
    "- our very simple baseline model assumes every client from district 51 is fraudulent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>client_catg</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>51</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>92.391486</td>\n",
       "      <td>94.413284</td>\n",
       "      <td>79.044952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>7.608514</td>\n",
       "      <td>5.586716</td>\n",
       "      <td>20.955048</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "client_catg         11         12         51\n",
       "target                                      \n",
       "0.0          92.391486  94.413284  79.044952\n",
       "1.0           7.608514   5.586716  20.955048"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def baseline_model(X):\n",
    "    y_pred = [0 if cat != 51 else 1 for cat in X.client_catg]\n",
    "    return y_pred\n",
    "\n",
    "# in district 51 the most fraudulents appear:\n",
    "pd.crosstab(df['target'], df['client_catg'], normalize='columns')*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score: 0.21\n",
      "ROC AUC: 0.52\n"
     ]
    }
   ],
   "source": [
    "# Select the features to use for modeling\n",
    "feature_cols = ['district','client_catg', 'region_group',\n",
    "       'tarif_type', 'counter_number',\n",
    "       'counter_statue', 'counter_code', 'reading_remarque',\n",
    "       'counter_coefficient', 'months_number', 'counter_type',\n",
    "       'total_consumption', 'invoice_year', 'mean_consumption_per_year', 'historical_mean_consumption']\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[feature_cols], df['target'], test_size=0.3, random_state=42)\n",
    "y_pred = baseline_model(X_test)\n",
    "\n",
    "print('F1-score:', precision_score(y_test, y_pred).round(2))\n",
    "print('ROC AUC:', roc_auc_score(y_test, y_pred).round(2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = ['district','client_catg', 'region_group',\n",
    "       'tarif_type', 'counter_number',\n",
    "       'counter_statue', 'counter_code', 'reading_remarque',\n",
    "       'counter_coefficient', 'months_number', 'counter_type',\n",
    "       'total_consumption', 'invoice_year', 'mean_consumption_per_year', 'historical_mean_consumption']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample the data to balance the classes\n",
    "\n",
    "# Separate majority and minority classes\n",
    "df_majority = df[df.target==0]\n",
    "df_minority = df[df.target==1]\n",
    "\n",
    "# Downsample majority class\n",
    "df_majority_downsampled = resample(df_majority, \n",
    "                                   replace=False,     # Sample without replacement\n",
    "                                   n_samples=len(df_minority),    # Match number in minority class\n",
    "                                   random_state=42)  # Reproducible results\n",
    "\n",
    "# Combine majority class with minority class\n",
    "df_downsampled = pd.concat([df_majority_downsampled, df_minority])\n",
    "\n",
    "# Split into X and y\n",
    "X_down = df_downsampled[feature_cols]\n",
    "y_down = df_downsampled['target']\n",
    "\n",
    "# Upsample minority class\n",
    "df_minority_upsampled = resample(df_minority, \n",
    "                                 replace=True,    # Sample with replacement\n",
    "                                 n_samples=len(df_majority),    # Match number in majority class\n",
    "                                 random_state=42)  # Reproducible results\n",
    "\n",
    "# Combine majority class with upsampled minority class\n",
    "df_upsampled = pd.concat([df_majority, df_minority_upsampled])\n",
    "\n",
    "# Split into X and y\n",
    "X_up = df_upsampled[feature_cols]\n",
    "y_up = df_upsampled['target']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_down, X_test_down, y_train_down, y_test_down = train_test_split(X_down, y_down, test_size=0.3, random_state=42)\n",
    "X_train_up, X_test_up, y_train_up, y_test_up = train_test_split(X_up, y_up, test_size=0.3, random_state=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale data\n",
    "\n",
    "# Instantiate the scaler\n",
    "scaler_down = StandardScaler()\n",
    "\n",
    "# Fit and transform the training data\n",
    "X_train_scaled_down = scaler_down.fit_transform(X_train_down)\n",
    "\n",
    "# Transform the test data using the same scaler\n",
    "X_test_scaled_down = scaler_down.transform(X_test_down)\n",
    "\n",
    "# scale data\n",
    "\n",
    "# Instantiate the scaler\n",
    "scaler_up = StandardScaler()\n",
    "\n",
    "# Fit and transform the training data\n",
    "X_train_scaled_up = scaler_up.fit_transform(X_train_up)\n",
    "\n",
    "# Transform the test data using the same scaler\n",
    "X_test_scaled_up = scaler_up.transform(X_test_up)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A model with better performance?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost with GridSearch / Downsampling / "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Accuracy: 0.69\n",
      "Precision: 0.69\n",
      "Recall: 0.69\n",
      "F1 Score: 0.69\n",
      "ROC AUC Score: 0.69\n"
     ]
    }
   ],
   "source": [
    "# Define XGBoost model with enable_categorical=True and tree_method='hist'\n",
    "xgb_model = xgb.XGBClassifier(objective='binary:logistic', seed=42, enable_categorical=True, tree_method='hist')\n",
    "\n",
    "# Define parameter grid for grid search\n",
    "param_grid = {\n",
    "    'objective': ['binary:logistic'],\n",
    "    'seed': [42],\n",
    "    'enable_categorical': [True],\n",
    "    'tree_method': ['hist'],\n",
    "    'n_estimators': [300],\n",
    "    'max_depth': [9],\n",
    "    'learning_rate': [0.1]\n",
    "}\n",
    "\n",
    "# Create GridSearchCV object\n",
    "clf = GridSearchCV(estimator=xgb_model, param_grid=param_grid, cv=5, n_jobs=-1, verbose=1)\n",
    "\n",
    "# Fit GridSearchCV object to training data\n",
    "clf.fit(X_train_scaled_down, y_train_down)\n",
    "\n",
    "# Predict on test data using best model\n",
    "y_pred = clf.predict(X_test_scaled_down)\n",
    "\n",
    "eda.print_metrics(y_test_down, y_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost with GridSearch / Upsampling / "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Accuracy: 0.71\n",
      "Precision: 0.71\n",
      "Recall: 0.72\n",
      "F1 Score: 0.72\n",
      "ROC AUC Score: 0.71\n"
     ]
    }
   ],
   "source": [
    "# Define XGBoost model with enable_categorical=True and tree_method='hist'\n",
    "xgb_model = xgb.XGBClassifier(objective='binary:logistic', seed=42, enable_categorical=True, tree_method='hist')\n",
    "\n",
    "# Define parameter grid for grid search\n",
    "param_grid = {\n",
    "    'objective': ['binary:logistic'],\n",
    "    'seed': [42],\n",
    "    'enable_categorical': [True],\n",
    "    'tree_method': ['hist'],\n",
    "    'n_estimators': [300],\n",
    "    'max_depth': [9],\n",
    "    'learning_rate': [0.1]\n",
    "}\n",
    "\n",
    "# Create GridSearchCV object\n",
    "clf = GridSearchCV(estimator=xgb_model, param_grid=param_grid, cv=5, n_jobs=-1, verbose=1)\n",
    "\n",
    "# Fit GridSearchCV object to training data\n",
    "clf.fit(X_train_scaled_up, y_train_up)\n",
    "\n",
    "# Predict on test data using best model\n",
    "y_pred = clf.predict(X_test_scaled_up)\n",
    "\n",
    "eda.print_metrics(y_test_up, y_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost with RandomSearchCV / Downscaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m random_model \u001b[39m=\u001b[39m RandomizedSearchCV(estimator\u001b[39m=\u001b[39mmodel, param_distributions\u001b[39m=\u001b[39mparam_grid, n_iter\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, cv\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, n_jobs\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, verbose\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     15\u001b[0m \u001b[39m# Fit the model to the training data\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m random_model\u001b[39m.\u001b[39;49mfit(X_train_scaled_down, y_train_down)\n\u001b[1;32m     18\u001b[0m \u001b[39mprint\u001b[39m(random_model\u001b[39m.\u001b[39mbest_params_)\n",
      "File \u001b[0;32m~/Documents/ds-fraud-detection/.venv/lib/python3.9/site-packages/sklearn/model_selection/_search.py:891\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    885\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[1;32m    886\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    887\u001b[0m     )\n\u001b[1;32m    889\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[0;32m--> 891\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[1;32m    893\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    894\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    895\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/Documents/ds-fraud-detection/.venv/lib/python3.9/site-packages/sklearn/model_selection/_search.py:1766\u001b[0m, in \u001b[0;36mRandomizedSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1764\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1765\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1766\u001b[0m     evaluate_candidates(\n\u001b[1;32m   1767\u001b[0m         ParameterSampler(\n\u001b[1;32m   1768\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_distributions, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_iter, random_state\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrandom_state\n\u001b[1;32m   1769\u001b[0m         )\n\u001b[1;32m   1770\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/ds-fraud-detection/.venv/lib/python3.9/site-packages/sklearn/model_selection/_search.py:838\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    831\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[1;32m    832\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    833\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    834\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[1;32m    835\u001b[0m         )\n\u001b[1;32m    836\u001b[0m     )\n\u001b[0;32m--> 838\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[1;32m    839\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    840\u001b[0m         clone(base_estimator),\n\u001b[1;32m    841\u001b[0m         X,\n\u001b[1;32m    842\u001b[0m         y,\n\u001b[1;32m    843\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[1;32m    844\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[1;32m    845\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[1;32m    846\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[1;32m    847\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[1;32m    848\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[1;32m    849\u001b[0m     )\n\u001b[1;32m    850\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[1;32m    851\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[1;32m    852\u001b[0m     )\n\u001b[1;32m    853\u001b[0m )\n\u001b[1;32m    855\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    856\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    857\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    858\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    859\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    860\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/ds-fraud-detection/.venv/lib/python3.9/site-packages/joblib/parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1095\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m   1097\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1098\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mretrieve()\n\u001b[1;32m   1099\u001b[0m \u001b[39m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m elapsed_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_start_time\n",
      "File \u001b[0;32m~/Documents/ds-fraud-detection/.venv/lib/python3.9/site-packages/joblib/parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    973\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    974\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, \u001b[39m'\u001b[39m\u001b[39msupports_timeout\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m--> 975\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout))\n\u001b[1;32m    976\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    977\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39mget())\n",
      "File \u001b[0;32m~/Documents/ds-fraud-detection/.venv/lib/python3.9/site-packages/joblib/_parallel_backends.py:567\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[1;32m    565\u001b[0m \u001b[39mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[1;32m    566\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 567\u001b[0m     \u001b[39mreturn\u001b[39;00m future\u001b[39m.\u001b[39;49mresult(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m    568\u001b[0m \u001b[39mexcept\u001b[39;00m CfTimeoutError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    569\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.8/lib/python3.9/concurrent/futures/_base.py:440\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[1;32m    438\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__get_result()\n\u001b[0;32m--> 440\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_condition\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[1;32m    442\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[1;32m    443\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.8/lib/python3.9/threading.py:312\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    311\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 312\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[1;32m    313\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    314\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Define best hyperparameters\n",
    "param_grid = {\n",
    "    'objective': ['binary:logistic'],\n",
    "    'tree_method': ['hist'],\n",
    "    'n_estimators': [100, 200, 300, 400, 500],\n",
    "    'max_depth': [2, 4, 6, 8, 10, 12, 14, 16, 18, 20],\n",
    "    'learning_rate': [1, 0.1, 0.01]\n",
    "}\n",
    "\n",
    "# Create XGBoost model with best hyperparameters\n",
    "model = xgb.XGBClassifier()\n",
    "\n",
    "random_model = RandomizedSearchCV(estimator=model, param_distributions=param_grid, n_iter=10, cv=5, n_jobs=-1, verbose=1)\n",
    "\n",
    "# Fit the model to the training data\n",
    "random_model.fit(X_train_scaled_down, y_train_down)\n",
    "\n",
    "print(random_model.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "DataFrame.dtypes for data must be int, float, bool or category. When categorical type is supplied, The experimental DMatrix parameter`enable_categorical` must be set to `True`.  Invalid columns:district: category, client_catg: category",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m rf_best\u001b[39m.\u001b[39mfit(X_train_scaled_down, y_train_down)\n\u001b[1;32m     10\u001b[0m \u001b[39m# Make predictions on the test data using the best classifier\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m y_pred_proba \u001b[39m=\u001b[39m rf_best\u001b[39m.\u001b[39;49mpredict_proba(X_test_down)\n\u001b[1;32m     13\u001b[0m \u001b[39m# Convert predicted probabilities to predicted class labels\u001b[39;00m\n\u001b[1;32m     14\u001b[0m y_pred \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39margmax(y_pred_proba, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/ds-fraud-detection/.venv/lib/python3.9/site-packages/xgboost/sklearn.py:1606\u001b[0m, in \u001b[0;36mXGBClassifier.predict_proba\u001b[0;34m(self, X, ntree_limit, validate_features, base_margin, iteration_range)\u001b[0m\n\u001b[1;32m   1604\u001b[0m     class_prob \u001b[39m=\u001b[39m softmax(raw_predt, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m   1605\u001b[0m     \u001b[39mreturn\u001b[39;00m class_prob\n\u001b[0;32m-> 1606\u001b[0m class_probs \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mpredict(\n\u001b[1;32m   1607\u001b[0m     X\u001b[39m=\u001b[39;49mX,\n\u001b[1;32m   1608\u001b[0m     ntree_limit\u001b[39m=\u001b[39;49mntree_limit,\n\u001b[1;32m   1609\u001b[0m     validate_features\u001b[39m=\u001b[39;49mvalidate_features,\n\u001b[1;32m   1610\u001b[0m     base_margin\u001b[39m=\u001b[39;49mbase_margin,\n\u001b[1;32m   1611\u001b[0m     iteration_range\u001b[39m=\u001b[39;49miteration_range,\n\u001b[1;32m   1612\u001b[0m )\n\u001b[1;32m   1613\u001b[0m \u001b[39m# If model is loaded from a raw booster there's no `n_classes_`\u001b[39;00m\n\u001b[1;32m   1614\u001b[0m \u001b[39mreturn\u001b[39;00m _cls_predict_proba(\n\u001b[1;32m   1615\u001b[0m     \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mn_classes_\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m0\u001b[39m), class_probs, np\u001b[39m.\u001b[39mvstack\n\u001b[1;32m   1616\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/ds-fraud-detection/.venv/lib/python3.9/site-packages/xgboost/sklearn.py:1114\u001b[0m, in \u001b[0;36mXGBModel.predict\u001b[0;34m(self, X, output_margin, ntree_limit, validate_features, base_margin, iteration_range)\u001b[0m\n\u001b[1;32m   1112\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_can_use_inplace_predict():\n\u001b[1;32m   1113\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1114\u001b[0m         predts \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_booster()\u001b[39m.\u001b[39;49minplace_predict(\n\u001b[1;32m   1115\u001b[0m             data\u001b[39m=\u001b[39;49mX,\n\u001b[1;32m   1116\u001b[0m             iteration_range\u001b[39m=\u001b[39;49miteration_range,\n\u001b[1;32m   1117\u001b[0m             predict_type\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mmargin\u001b[39;49m\u001b[39m\"\u001b[39;49m \u001b[39mif\u001b[39;49;00m output_margin \u001b[39melse\u001b[39;49;00m \u001b[39m\"\u001b[39;49m\u001b[39mvalue\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m   1118\u001b[0m             missing\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmissing,\n\u001b[1;32m   1119\u001b[0m             base_margin\u001b[39m=\u001b[39;49mbase_margin,\n\u001b[1;32m   1120\u001b[0m             validate_features\u001b[39m=\u001b[39;49mvalidate_features,\n\u001b[1;32m   1121\u001b[0m         )\n\u001b[1;32m   1122\u001b[0m         \u001b[39mif\u001b[39;00m _is_cupy_array(predts):\n\u001b[1;32m   1123\u001b[0m             \u001b[39mimport\u001b[39;00m \u001b[39mcupy\u001b[39;00m  \u001b[39m# pylint: disable=import-error\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/ds-fraud-detection/.venv/lib/python3.9/site-packages/xgboost/core.py:2284\u001b[0m, in \u001b[0;36mBooster.inplace_predict\u001b[0;34m(self, data, iteration_range, predict_type, missing, validate_features, base_margin, strict_shape)\u001b[0m\n\u001b[1;32m   2282\u001b[0m enable_categorical \u001b[39m=\u001b[39m _has_categorical(\u001b[39mself\u001b[39m, data)\n\u001b[1;32m   2283\u001b[0m \u001b[39mif\u001b[39;00m _is_pandas_df(data):\n\u001b[0;32m-> 2284\u001b[0m     data, fns, _ \u001b[39m=\u001b[39m _transform_pandas_df(data, enable_categorical)\n\u001b[1;32m   2285\u001b[0m     \u001b[39mif\u001b[39;00m validate_features:\n\u001b[1;32m   2286\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_features(fns)\n",
      "File \u001b[0;32m~/Documents/ds-fraud-detection/.venv/lib/python3.9/site-packages/xgboost/data.py:391\u001b[0m, in \u001b[0;36m_transform_pandas_df\u001b[0;34m(data, enable_categorical, feature_names, feature_types, meta, meta_type)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapi\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtypes\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m    380\u001b[0m     is_sparse,\n\u001b[1;32m    381\u001b[0m     is_categorical_dtype,\n\u001b[1;32m    382\u001b[0m )\n\u001b[1;32m    384\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mall\u001b[39m(\n\u001b[1;32m    385\u001b[0m     dtype\u001b[39m.\u001b[39mname \u001b[39min\u001b[39;00m _pandas_dtype_mapper\n\u001b[1;32m    386\u001b[0m     \u001b[39mor\u001b[39;00m is_sparse(dtype)\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    389\u001b[0m     \u001b[39mfor\u001b[39;00m dtype \u001b[39min\u001b[39;00m data\u001b[39m.\u001b[39mdtypes\n\u001b[1;32m    390\u001b[0m ):\n\u001b[0;32m--> 391\u001b[0m     _invalid_dataframe_dtype(data)\n\u001b[1;32m    393\u001b[0m feature_names, feature_types \u001b[39m=\u001b[39m _pandas_feature_info(\n\u001b[1;32m    394\u001b[0m     data, meta, feature_names, feature_types, enable_categorical\n\u001b[1;32m    395\u001b[0m )\n\u001b[1;32m    397\u001b[0m transformed \u001b[39m=\u001b[39m _pandas_cat_null(data)\n",
      "File \u001b[0;32m~/Documents/ds-fraud-detection/.venv/lib/python3.9/site-packages/xgboost/data.py:283\u001b[0m, in \u001b[0;36m_invalid_dataframe_dtype\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    281\u001b[0m type_err \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mDataFrame.dtypes for data must be int, float, bool or category.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    282\u001b[0m msg \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\"\"\u001b[39m\u001b[39m{\u001b[39;00mtype_err\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00m_ENABLE_CAT_ERR\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00merr\u001b[39m}\u001b[39;00m\u001b[39m\"\"\"\u001b[39m\n\u001b[0;32m--> 283\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg)\n",
      "\u001b[0;31mValueError\u001b[0m: DataFrame.dtypes for data must be int, float, bool or category. When categorical type is supplied, The experimental DMatrix parameter`enable_categorical` must be set to `True`.  Invalid columns:district: category, client_catg: category"
     ]
    }
   ],
   "source": [
    "# Get the best hyperparameters\n",
    "best_params = random_model.best_params_\n",
    "\n",
    "# Create a new random forest classifier with the best hyperparameters\n",
    "rf_best = xgb.XGBClassifier(**best_params, enable_categorical=True)\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "rf_best.fit(X_train_scaled_down, y_train_down)\n",
    "\n",
    "# Make predictions on the test data using the best classifier\n",
    "y_pred_proba = rf_best.predict_proba(X_test_down)\n",
    "\n",
    "# Convert predicted probabilities to predicted class labels\n",
    "y_pred = np.argmax(y_pred_proba, axis=1)\n",
    "\n",
    "eda.print_metrics(y_test_down, y_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.71\n",
      "Precision: 0.71\n",
      "Recall: 0.72\n",
      "F1 Score: 0.72\n",
      "ROC AUC Score: 0.71\n"
     ]
    }
   ],
   "source": [
    "# Fit logistic regression model on the training data\n",
    "lr = LogisticRegression(random_state=42)\n",
    "lr.fit(X_train_scaled_down, y_train_down)\n",
    "\n",
    "# Predict on test data using logistic regression model\n",
    "y_pred_lr = lr.predict(X_test_scaled_down)\n",
    "\n",
    "eda.print_metrics(y_test_down, y_pred)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RF with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   25.8s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   26.2s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   26.2s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   27.1s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   27.5s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   27.6s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   27.8s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   27.8s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:  3.6min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:  3.6min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:  3.6min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:  3.6min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:  3.6min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=8)]: Done 300 out of 300 | elapsed:    3.5s finished\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=8)]: Done 300 out of 300 | elapsed:    3.7s finished\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=8)]: Done 300 out of 300 | elapsed:    3.7s finished\n",
      "[Parallel(n_jobs=8)]: Done 300 out of 300 | elapsed:    3.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done 300 out of 300 | elapsed:    3.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   25.5s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   26.9s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   26.8s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   26.4s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   26.6s\n",
      "[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed:  4.7min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed:  4.8min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=8)]: Done 400 out of 400 | elapsed:    4.7s finished\n",
      "[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed:  4.8min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done 400 out of 400 | elapsed:    4.9s finished\n",
      "[Parallel(n_jobs=8)]: Done 400 out of 400 | elapsed:    4.8s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   27.0s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   26.2s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   37.7s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed:  5.1min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    2.7s\n",
      "[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed:  5.2min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=8)]: Done 400 out of 400 | elapsed:    6.7s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done 400 out of 400 | elapsed:    6.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:  5.7min\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:  5.7min\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:  5.8min\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   46.1s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   47.0s\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:  6.7min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:  6.7min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:  6.7min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    2.7s\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    7.1s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    7.1s\n",
      "[Parallel(n_jobs=8)]: Done 500 out of 500 | elapsed:    8.3s finished\n",
      "[Parallel(n_jobs=8)]: Done 500 out of 500 | elapsed:    8.2s finished\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    7.1s\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done 500 out of 500 | elapsed:    8.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:  5.9min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    5.8s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:  6.1min\n",
      "[Parallel(n_jobs=8)]: Done 300 out of 300 | elapsed:    9.5s finished\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:  6.1min\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   52.0s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   52.5s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   53.7s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   48.5s\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:  7.1min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:  7.1min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    2.7s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    6.6s\n",
      "[Parallel(n_jobs=8)]: Done 500 out of 500 | elapsed:    7.7s finished\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    6.5s\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done 500 out of 500 | elapsed:    7.6s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   41.0s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   40.8s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:  5.8min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:  5.8min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    3.9s\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=8)]: Done 300 out of 300 | elapsed:    6.5s finished\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    4.1s\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done 300 out of 300 | elapsed:    6.6s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   39.2s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   40.3s\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:  5.6min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:  5.6min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    4.5s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    4.6s\n",
      "[Parallel(n_jobs=8)]: Done 300 out of 300 | elapsed:    7.5s finished\n",
      "[Parallel(n_jobs=8)]: Done 300 out of 300 | elapsed:    7.4s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   42.8s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   44.3s\n",
      "[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed:  7.4min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    4.8s\n",
      "[Parallel(n_jobs=8)]: Done 400 out of 400 | elapsed:   10.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed:  7.3min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    4.5s\n",
      "[Parallel(n_jobs=8)]: Done 400 out of 400 | elapsed:    9.9s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   40.3s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   40.8s\n",
      "[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed:  7.2min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed:  7.2min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    4.2s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    4.1s\n",
      "[Parallel(n_jobs=8)]: Done 400 out of 400 | elapsed:    9.1s finished\n",
      "[Parallel(n_jobs=8)]: Done 400 out of 400 | elapsed:    9.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   51.4s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   52.2s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed:  7.4min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    4.4s\n",
      "[Parallel(n_jobs=8)]: Done 400 out of 400 | elapsed:    9.4s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:  8.0min\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   48.4s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  4.1min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  4.1min\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:  9.2min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    5.3s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:   12.3s\n",
      "[Parallel(n_jobs=8)]: Done 500 out of 500 | elapsed:   14.4s finished\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:  8.1min\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:  8.1min\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   52.8s\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:  9.3min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:  9.2min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    4.4s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    4.3s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:   10.3s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:   10.2s\n",
      "[Parallel(n_jobs=8)]: Done 500 out of 500 | elapsed:   11.7s finished\n",
      "[Parallel(n_jobs=8)]: Done 500 out of 500 | elapsed:   11.6s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:  6.6min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:  6.6min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:  7.9min\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    7.5s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    7.6s\n",
      "[Parallel(n_jobs=8)]: Done 300 out of 300 | elapsed:   12.4s finished\n",
      "[Parallel(n_jobs=8)]: Done 300 out of 300 | elapsed:   12.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:  7.9min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   45.0s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   45.8s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   47.2s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   47.9s\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:  9.0min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    4.2s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:   10.1s\n",
      "[Parallel(n_jobs=8)]: Done 500 out of 500 | elapsed:   11.7s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:  9.0min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    4.1s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    9.9s\n",
      "[Parallel(n_jobs=8)]: Done 500 out of 500 | elapsed:   11.4s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   47.9s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   47.3s\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:  6.3min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    7.9s\n",
      "[Parallel(n_jobs=8)]: Done 300 out of 300 | elapsed:   12.9s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   49.0s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:  6.3min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    7.6s\n",
      "[Parallel(n_jobs=8)]: Done 300 out of 300 | elapsed:   12.4s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   47.9s\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:  6.2min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    7.7s\n",
      "[Parallel(n_jobs=8)]: Done 300 out of 300 | elapsed:   12.7s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   48.6s\n",
      "[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed:  8.3min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    8.0s\n",
      "[Parallel(n_jobs=8)]: Done 400 out of 400 | elapsed:   17.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed:  8.3min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed:  8.4min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    8.8s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    9.2s\n",
      "[Parallel(n_jobs=8)]: Done 400 out of 400 | elapsed:   19.6s finished\n",
      "[Parallel(n_jobs=8)]: Done 400 out of 400 | elapsed:   19.4s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   51.4s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   47.2s\n",
      "[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed:  8.4min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    8.0s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed:  8.4min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done 400 out of 400 | elapsed:   16.6s finished\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    6.9s\n",
      "[Parallel(n_jobs=8)]: Done 400 out of 400 | elapsed:   15.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:  8.6min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:  9.6min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    5.4s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:   13.4s\n",
      "[Parallel(n_jobs=8)]: Done 500 out of 500 | elapsed:   15.3s finished\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:  8.1min\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:  7.4min\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:  8.8min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    8.4s\n",
      "[Parallel(n_jobs=8)]: Done 500 out of 500 | elapsed:   10.1s finished\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:  8.0min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    7.9s\n",
      "[Parallel(n_jobs=8)]: Done 500 out of 500 | elapsed:    9.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:  6.1min\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:  5.6min\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:  6.5min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    4.8s\n",
      "[Parallel(n_jobs=8)]: Done 500 out of 500 | elapsed:    5.5s finished\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:  5.9min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=8)]: Done 500 out of 500 | elapsed:    3.4s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   10.3s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   42.7s\n",
      "[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed:  1.6min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters:  {'max_depth': 20, 'n_estimators': 400, 'n_jobs': -1, 'random_state': 42, 'verbose': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=8)]: Done 400 out of 400 | elapsed:    6.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.66\n",
      "Precision: 0.66\n",
      "Recall: 0.65\n",
      "F1 Score: 0.65\n",
      "ROC AUC Score: 0.66\n"
     ]
    }
   ],
   "source": [
    "rf_model = RandomForestClassifier(n_estimators=100, max_depth=9, random_state=42)\n",
    "\n",
    "rf_model.fit(X_train_scaled_down, y_train_down)\n",
    "\n",
    "y_pred = rf_model.predict(X_test_scaled_down)\n",
    "\n",
    "# Define parameter grid for grid search\n",
    "param_grid = {\n",
    "    'random_state': [42],\n",
    "    'n_estimators': [300, 400, 500],\n",
    "    'max_depth': [10, 15, 20],\n",
    "    'verbose': [1],\n",
    "    'n_jobs': [-1],\n",
    "}\n",
    "\n",
    "# Create GridSearchCV object\n",
    "clf = GridSearchCV(estimator=rf_model, param_grid=param_grid, cv=5, n_jobs=-1, verbose=1)\n",
    "\n",
    "# Fit GridSearchCV object to training data\n",
    "clf.fit(X_train_scaled_down, y_train_down)\n",
    "\n",
    "print(\"Best hyperparameters: \", clf.best_params_)\n",
    "\n",
    "# Predict on test data using best model\n",
    "y_pred = clf.predict(X_test_scaled_down)\n",
    "\n",
    "eda.print_metrics(y_test_down, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters:  {'max_depth': 20, 'n_estimators': 400, 'n_jobs': -1, 'random_state': 42, 'verbose': 1}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best hyperparameters: \", clf.best_params_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest with Scikit-Optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 32\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39m-\u001b[39mtest_f1\n\u001b[1;32m     31\u001b[0m \u001b[39m# Run Bayesian optimization using the objective function and search space\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m res \u001b[39m=\u001b[39m gp_minimize(objective, space, n_calls\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m, random_state\u001b[39m=\u001b[39;49m\u001b[39m42\u001b[39;49m)\n\u001b[1;32m     34\u001b[0m \u001b[39m# Print best hyperparameters and evaluation metrics on test set\u001b[39;00m\n\u001b[1;32m     35\u001b[0m best_params \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mn_estimators\u001b[39m\u001b[39m'\u001b[39m: res\u001b[39m.\u001b[39mx[\u001b[39m0\u001b[39m], \u001b[39m'\u001b[39m\u001b[39mmax_depth\u001b[39m\u001b[39m'\u001b[39m: res\u001b[39m.\u001b[39mx[\u001b[39m1\u001b[39m], \u001b[39m'\u001b[39m\u001b[39mmin_samples_split\u001b[39m\u001b[39m'\u001b[39m: res\u001b[39m.\u001b[39mx[\u001b[39m2\u001b[39m], \u001b[39m'\u001b[39m\u001b[39mrandom_state\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m42\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mverbose\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m1\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mn_jobs\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m}\n",
      "File \u001b[0;32m~/Documents/ds-fraud-detection/.venv/lib/python3.9/site-packages/skopt/optimizer/gp.py:259\u001b[0m, in \u001b[0;36mgp_minimize\u001b[0;34m(func, dimensions, base_estimator, n_calls, n_random_starts, n_initial_points, initial_point_generator, acq_func, acq_optimizer, x0, y0, random_state, verbose, callback, n_points, n_restarts_optimizer, xi, kappa, noise, n_jobs, model_queue_size)\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[39mif\u001b[39;00m base_estimator \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    255\u001b[0m     base_estimator \u001b[39m=\u001b[39m cook_estimator(\n\u001b[1;32m    256\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mGP\u001b[39m\u001b[39m\"\u001b[39m, space\u001b[39m=\u001b[39mspace, random_state\u001b[39m=\u001b[39mrng\u001b[39m.\u001b[39mrandint(\u001b[39m0\u001b[39m, np\u001b[39m.\u001b[39miinfo(np\u001b[39m.\u001b[39mint32)\u001b[39m.\u001b[39mmax),\n\u001b[1;32m    257\u001b[0m         noise\u001b[39m=\u001b[39mnoise)\n\u001b[0;32m--> 259\u001b[0m \u001b[39mreturn\u001b[39;00m base_minimize(\n\u001b[1;32m    260\u001b[0m     func, space, base_estimator\u001b[39m=\u001b[39;49mbase_estimator,\n\u001b[1;32m    261\u001b[0m     acq_func\u001b[39m=\u001b[39;49macq_func,\n\u001b[1;32m    262\u001b[0m     xi\u001b[39m=\u001b[39;49mxi, kappa\u001b[39m=\u001b[39;49mkappa, acq_optimizer\u001b[39m=\u001b[39;49macq_optimizer, n_calls\u001b[39m=\u001b[39;49mn_calls,\n\u001b[1;32m    263\u001b[0m     n_points\u001b[39m=\u001b[39;49mn_points, n_random_starts\u001b[39m=\u001b[39;49mn_random_starts,\n\u001b[1;32m    264\u001b[0m     n_initial_points\u001b[39m=\u001b[39;49mn_initial_points,\n\u001b[1;32m    265\u001b[0m     initial_point_generator\u001b[39m=\u001b[39;49minitial_point_generator,\n\u001b[1;32m    266\u001b[0m     n_restarts_optimizer\u001b[39m=\u001b[39;49mn_restarts_optimizer,\n\u001b[1;32m    267\u001b[0m     x0\u001b[39m=\u001b[39;49mx0, y0\u001b[39m=\u001b[39;49my0, random_state\u001b[39m=\u001b[39;49mrng, verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m    268\u001b[0m     callback\u001b[39m=\u001b[39;49mcallback, n_jobs\u001b[39m=\u001b[39;49mn_jobs, model_queue_size\u001b[39m=\u001b[39;49mmodel_queue_size)\n",
      "File \u001b[0;32m~/Documents/ds-fraud-detection/.venv/lib/python3.9/site-packages/skopt/optimizer/base.py:299\u001b[0m, in \u001b[0;36mbase_minimize\u001b[0;34m(func, dimensions, base_estimator, n_calls, n_random_starts, n_initial_points, initial_point_generator, acq_func, acq_optimizer, x0, y0, random_state, verbose, callback, n_points, n_restarts_optimizer, xi, kappa, n_jobs, model_queue_size)\u001b[0m\n\u001b[1;32m    297\u001b[0m \u001b[39mfor\u001b[39;00m n \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_calls):\n\u001b[1;32m    298\u001b[0m     next_x \u001b[39m=\u001b[39m optimizer\u001b[39m.\u001b[39mask()\n\u001b[0;32m--> 299\u001b[0m     next_y \u001b[39m=\u001b[39m func(next_x)\n\u001b[1;32m    300\u001b[0m     result \u001b[39m=\u001b[39m optimizer\u001b[39m.\u001b[39mtell(next_x, next_y)\n\u001b[1;32m    301\u001b[0m     result\u001b[39m.\u001b[39mspecs \u001b[39m=\u001b[39m specs\n",
      "File \u001b[0;32m~/Documents/ds-fraud-detection/.venv/lib/python3.9/site-packages/skopt/utils.py:789\u001b[0m, in \u001b[0;36muse_named_args.<locals>.decorator.<locals>.wrapper\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    786\u001b[0m arg_dict \u001b[39m=\u001b[39m {dim\u001b[39m.\u001b[39mname: value \u001b[39mfor\u001b[39;00m dim, value \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(dimensions, x)}\n\u001b[1;32m    788\u001b[0m \u001b[39m# Call the wrapped objective function with the named arguments.\u001b[39;00m\n\u001b[0;32m--> 789\u001b[0m objective_value \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49marg_dict)\n\u001b[1;32m    791\u001b[0m \u001b[39mreturn\u001b[39;00m objective_value\n",
      "Cell \u001b[0;32mIn[43], line 22\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(n_estimators, max_depth, min_samples_split)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[39m@use_named_args\u001b[39m(space)\n\u001b[1;32m     19\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mobjective\u001b[39m(n_estimators, max_depth, min_samples_split):\n\u001b[1;32m     20\u001b[0m     \u001b[39m# Create model with specified hyperparameters\u001b[39;00m\n\u001b[1;32m     21\u001b[0m     rf_model \u001b[39m=\u001b[39m RandomForestClassifier(n_estimators\u001b[39m=\u001b[39mn_estimators, max_depth\u001b[39m=\u001b[39mmax_depth, min_samples_split\u001b[39m=\u001b[39mmin_samples_split, random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m)\n\u001b[0;32m---> 22\u001b[0m     rf_model\u001b[39m.\u001b[39;49mfit(X_train_scaled, y_train_down)\n\u001b[1;32m     24\u001b[0m     \u001b[39m# Make predictions on test data and compute evaluation metrics\u001b[39;00m\n\u001b[1;32m     25\u001b[0m     y_pred \u001b[39m=\u001b[39m rf_model\u001b[39m.\u001b[39mpredict(X_test_scaled)\n",
      "File \u001b[0;32m~/Documents/ds-fraud-detection/.venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:450\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    439\u001b[0m trees \u001b[39m=\u001b[39m [\n\u001b[1;32m    440\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_estimator(append\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, random_state\u001b[39m=\u001b[39mrandom_state)\n\u001b[1;32m    441\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_more_estimators)\n\u001b[1;32m    442\u001b[0m ]\n\u001b[1;32m    444\u001b[0m \u001b[39m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[1;32m    445\u001b[0m \u001b[39m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[1;32m    446\u001b[0m \u001b[39m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[1;32m    447\u001b[0m \u001b[39m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[1;32m    448\u001b[0m \u001b[39m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[1;32m    449\u001b[0m \u001b[39m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[0;32m--> 450\u001b[0m trees \u001b[39m=\u001b[39m Parallel(\n\u001b[1;32m    451\u001b[0m     n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs,\n\u001b[1;32m    452\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[1;32m    453\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m_joblib_parallel_args(prefer\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mthreads\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    454\u001b[0m )(\n\u001b[1;32m    455\u001b[0m     delayed(_parallel_build_trees)(\n\u001b[1;32m    456\u001b[0m         t,\n\u001b[1;32m    457\u001b[0m         \u001b[39mself\u001b[39;49m,\n\u001b[1;32m    458\u001b[0m         X,\n\u001b[1;32m    459\u001b[0m         y,\n\u001b[1;32m    460\u001b[0m         sample_weight,\n\u001b[1;32m    461\u001b[0m         i,\n\u001b[1;32m    462\u001b[0m         \u001b[39mlen\u001b[39;49m(trees),\n\u001b[1;32m    463\u001b[0m         verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[1;32m    464\u001b[0m         class_weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclass_weight,\n\u001b[1;32m    465\u001b[0m         n_samples_bootstrap\u001b[39m=\u001b[39;49mn_samples_bootstrap,\n\u001b[1;32m    466\u001b[0m     )\n\u001b[1;32m    467\u001b[0m     \u001b[39mfor\u001b[39;49;00m i, t \u001b[39min\u001b[39;49;00m \u001b[39menumerate\u001b[39;49m(trees)\n\u001b[1;32m    468\u001b[0m )\n\u001b[1;32m    470\u001b[0m \u001b[39m# Collect newly grown trees\u001b[39;00m\n\u001b[1;32m    471\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_\u001b[39m.\u001b[39mextend(trees)\n",
      "File \u001b[0;32m~/Documents/ds-fraud-detection/.venv/lib/python3.9/site-packages/joblib/parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1085\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1086\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1088\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[1;32m   1089\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[1;32m   1091\u001b[0m \u001b[39mif\u001b[39;00m pre_dispatch \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   1092\u001b[0m     \u001b[39m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[1;32m   1093\u001b[0m     \u001b[39m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[1;32m   1094\u001b[0m     \u001b[39m# consumption.\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/ds-fraud-detection/.venv/lib/python3.9/site-packages/joblib/parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    900\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 901\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[1;32m    902\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/ds-fraud-detection/.venv/lib/python3.9/site-packages/joblib/parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    818\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[0;32m--> 819\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[1;32m    820\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    821\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    822\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    823\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    824\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m~/Documents/ds-fraud-detection/.venv/lib/python3.9/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[1;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m~/Documents/ds-fraud-detection/.venv/lib/python3.9/site-packages/joblib/_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[1;32m    595\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    596\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 597\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[0;32m~/Documents/ds-fraud-detection/.venv/lib/python3.9/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/Documents/ds-fraud-detection/.venv/lib/python3.9/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/Documents/ds-fraud-detection/.venv/lib/python3.9/site-packages/sklearn/utils/fixes.py:216\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    215\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig):\n\u001b[0;32m--> 216\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Documents/ds-fraud-detection/.venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:185\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[39melif\u001b[39;00m class_weight \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbalanced_subsample\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    183\u001b[0m         curr_sample_weight \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m compute_sample_weight(\u001b[39m\"\u001b[39m\u001b[39mbalanced\u001b[39m\u001b[39m\"\u001b[39m, y, indices\u001b[39m=\u001b[39mindices)\n\u001b[0;32m--> 185\u001b[0m     tree\u001b[39m.\u001b[39;49mfit(X, y, sample_weight\u001b[39m=\u001b[39;49mcurr_sample_weight, check_input\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    186\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    187\u001b[0m     tree\u001b[39m.\u001b[39mfit(X, y, sample_weight\u001b[39m=\u001b[39msample_weight, check_input\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/Documents/ds-fraud-detection/.venv/lib/python3.9/site-packages/sklearn/tree/_classes.py:937\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    899\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\n\u001b[1;32m    900\u001b[0m     \u001b[39mself\u001b[39m, X, y, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, check_input\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, X_idx_sorted\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mdeprecated\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    901\u001b[0m ):\n\u001b[1;32m    902\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[1;32m    903\u001b[0m \n\u001b[1;32m    904\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    934\u001b[0m \u001b[39m        Fitted estimator.\u001b[39;00m\n\u001b[1;32m    935\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 937\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m    938\u001b[0m         X,\n\u001b[1;32m    939\u001b[0m         y,\n\u001b[1;32m    940\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m    941\u001b[0m         check_input\u001b[39m=\u001b[39;49mcheck_input,\n\u001b[1;32m    942\u001b[0m         X_idx_sorted\u001b[39m=\u001b[39;49mX_idx_sorted,\n\u001b[1;32m    943\u001b[0m     )\n\u001b[1;32m    944\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/Documents/ds-fraud-detection/.venv/lib/python3.9/site-packages/sklearn/tree/_classes.py:420\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    410\u001b[0m     builder \u001b[39m=\u001b[39m BestFirstTreeBuilder(\n\u001b[1;32m    411\u001b[0m         splitter,\n\u001b[1;32m    412\u001b[0m         min_samples_split,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    417\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmin_impurity_decrease,\n\u001b[1;32m    418\u001b[0m     )\n\u001b[0;32m--> 420\u001b[0m builder\u001b[39m.\u001b[39;49mbuild(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtree_, X, y, sample_weight)\n\u001b[1;32m    422\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_outputs_ \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m is_classifier(\u001b[39mself\u001b[39m):\n\u001b[1;32m    423\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_[\u001b[39m0\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Define hyperparameter search space\n",
    "space = [Integer(100, 400, name='n_estimators'),\n",
    "         Integer(3, 11, name='max_depth'),\n",
    "         Integer(2, 15, name='min_samples_split')]\n",
    "\n",
    "# Define objective function to minimize (in this case, negative F1 score)\n",
    "@use_named_args(space)\n",
    "def objective(n_estimators, max_depth, min_samples_split):\n",
    "    # Create model with specified hyperparameters\n",
    "    rf_model = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, min_samples_split=min_samples_split, random_state=42)\n",
    "    rf_model.fit(X_train_scaled_down, y_train_down)\n",
    "    \n",
    "    # Make predictions on test data and compute evaluation metrics\n",
    "    y_pred = rf_model.predict(X_test_scaled_down)\n",
    "    test_f1 = f1_score(y_test_down, y_pred, average='macro')\n",
    "    \n",
    "    # Return negative F1 score (to be minimized)\n",
    "    return -test_f1\n",
    "\n",
    "# Run Bayesian optimization using the objective function and search space\n",
    "res = gp_minimize(objective, space, n_calls=50, random_state=42)\n",
    "\n",
    "# Print best hyperparameters and evaluation metrics on test set\n",
    "best_params = {'n_estimators': res.x[0],\n",
    "                'max_depth': res.x[1],\n",
    "                'min_samples_split': res.x[2],\n",
    "                'random_state': 42,\n",
    "                'verbose': 1,\n",
    "                'n_jobs': -1}\n",
    "\n",
    "eda.print_metrics(y_test_down, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
