{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all modules needed\n",
    "import models.eda as eda\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, Normalizer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "from sklearn.utils import resample\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from skopt import gp_minimize\n",
    "from skopt.space import Real, Integer\n",
    "from skopt.utils import use_named_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s5/ccqphxw12ql_3b8zcycpgnym0000gn/T/ipykernel_8845/1235657692.py:3: DtypeWarning: Columns (4) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  invoice = eda.load_data(\"data/train/invoice_train.csv\")\n"
     ]
    }
   ],
   "source": [
    "# df_client and df_invoice are being loaded from the data folder\n",
    "client = eda.load_data(\"data/train/client_train.csv\")\n",
    "invoice = eda.load_data(\"data/train/invoice_train.csv\")\n",
    "df = eda.feature_change(client, invoice)\n",
    "df = eda.get_mean_consumption(df)\n",
    "df = eda.get_historical_mean(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>district</th>\n",
       "      <th>client_id</th>\n",
       "      <th>client_catg</th>\n",
       "      <th>region</th>\n",
       "      <th>creation_date</th>\n",
       "      <th>target</th>\n",
       "      <th>region_group</th>\n",
       "      <th>coop_time</th>\n",
       "      <th>invoice_date</th>\n",
       "      <th>tarif_type</th>\n",
       "      <th>...</th>\n",
       "      <th>reading_remarque</th>\n",
       "      <th>counter_coefficient</th>\n",
       "      <th>months_number</th>\n",
       "      <th>counter_type</th>\n",
       "      <th>invoice_month</th>\n",
       "      <th>invoice_year</th>\n",
       "      <th>is_weekday</th>\n",
       "      <th>total_consumption</th>\n",
       "      <th>mean_consumption_per_year</th>\n",
       "      <th>historical_mean_consumption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>101</td>\n",
       "      <td>1994-12-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>200</td>\n",
       "      <td>288</td>\n",
       "      <td>2005-10-17</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>2005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>124</td>\n",
       "      <td>124.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>101</td>\n",
       "      <td>1994-12-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>200</td>\n",
       "      <td>288</td>\n",
       "      <td>2006-10-18</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>2006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>159</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>124.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>101</td>\n",
       "      <td>1994-12-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>200</td>\n",
       "      <td>288</td>\n",
       "      <td>2006-06-23</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>141.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>101</td>\n",
       "      <td>1994-12-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>200</td>\n",
       "      <td>288</td>\n",
       "      <td>2006-02-24</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>141</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>148.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>101</td>\n",
       "      <td>1994-12-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>200</td>\n",
       "      <td>288</td>\n",
       "      <td>2007-02-26</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2007</td>\n",
       "      <td>0.0</td>\n",
       "      <td>182</td>\n",
       "      <td>232.666667</td>\n",
       "      <td>146.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>101</td>\n",
       "      <td>1994-12-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>200</td>\n",
       "      <td>288</td>\n",
       "      <td>2007-10-25</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>2007</td>\n",
       "      <td>0.0</td>\n",
       "      <td>276</td>\n",
       "      <td>232.666667</td>\n",
       "      <td>153.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>101</td>\n",
       "      <td>1994-12-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>200</td>\n",
       "      <td>288</td>\n",
       "      <td>2007-06-27</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2007</td>\n",
       "      <td>0.0</td>\n",
       "      <td>240</td>\n",
       "      <td>232.666667</td>\n",
       "      <td>174.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>101</td>\n",
       "      <td>1994-12-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>200</td>\n",
       "      <td>288</td>\n",
       "      <td>2008-01-04</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2008</td>\n",
       "      <td>0.0</td>\n",
       "      <td>277</td>\n",
       "      <td>207.333333</td>\n",
       "      <td>183.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>101</td>\n",
       "      <td>1994-12-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>200</td>\n",
       "      <td>288</td>\n",
       "      <td>2008-07-28</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2008</td>\n",
       "      <td>0.0</td>\n",
       "      <td>171</td>\n",
       "      <td>207.333333</td>\n",
       "      <td>195.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>101</td>\n",
       "      <td>1994-12-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>200</td>\n",
       "      <td>288</td>\n",
       "      <td>2008-11-25</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>2008</td>\n",
       "      <td>0.0</td>\n",
       "      <td>174</td>\n",
       "      <td>207.333333</td>\n",
       "      <td>192.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>101</td>\n",
       "      <td>1994-12-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>200</td>\n",
       "      <td>288</td>\n",
       "      <td>2009-11-24</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>2009</td>\n",
       "      <td>0.0</td>\n",
       "      <td>267</td>\n",
       "      <td>298.000000</td>\n",
       "      <td>190.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>101</td>\n",
       "      <td>1994-12-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>200</td>\n",
       "      <td>288</td>\n",
       "      <td>2009-07-27</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2009</td>\n",
       "      <td>0.0</td>\n",
       "      <td>312</td>\n",
       "      <td>298.000000</td>\n",
       "      <td>197.545455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>101</td>\n",
       "      <td>1994-12-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>200</td>\n",
       "      <td>288</td>\n",
       "      <td>2009-01-04</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2009</td>\n",
       "      <td>1.0</td>\n",
       "      <td>315</td>\n",
       "      <td>298.000000</td>\n",
       "      <td>207.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>101</td>\n",
       "      <td>1994-12-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>200</td>\n",
       "      <td>288</td>\n",
       "      <td>2010-07-22</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>278</td>\n",
       "      <td>262.666667</td>\n",
       "      <td>215.384615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>101</td>\n",
       "      <td>1994-12-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>200</td>\n",
       "      <td>288</td>\n",
       "      <td>2010-03-29</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>276</td>\n",
       "      <td>262.666667</td>\n",
       "      <td>219.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>101</td>\n",
       "      <td>1994-12-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>200</td>\n",
       "      <td>288</td>\n",
       "      <td>2010-11-24</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>2010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>234</td>\n",
       "      <td>262.666667</td>\n",
       "      <td>223.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>101</td>\n",
       "      <td>1994-12-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>200</td>\n",
       "      <td>288</td>\n",
       "      <td>2011-11-22</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>2011</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1082</td>\n",
       "      <td>988.333333</td>\n",
       "      <td>224.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>101</td>\n",
       "      <td>1994-12-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>200</td>\n",
       "      <td>288</td>\n",
       "      <td>2011-07-22</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2011</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1386</td>\n",
       "      <td>988.333333</td>\n",
       "      <td>274.705882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>101</td>\n",
       "      <td>1994-12-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>200</td>\n",
       "      <td>288</td>\n",
       "      <td>2011-03-30</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2011</td>\n",
       "      <td>0.0</td>\n",
       "      <td>497</td>\n",
       "      <td>988.333333</td>\n",
       "      <td>336.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>101</td>\n",
       "      <td>1994-12-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>200</td>\n",
       "      <td>288</td>\n",
       "      <td>2012-03-27</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>292</td>\n",
       "      <td>602.000000</td>\n",
       "      <td>344.894737</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   district  client_id client_catg region creation_date  target  region_group  \\\n",
       "0        60          0          11    101    1994-12-31     0.0           200   \n",
       "1        60          0          11    101    1994-12-31     0.0           200   \n",
       "2        60          0          11    101    1994-12-31     0.0           200   \n",
       "3        60          0          11    101    1994-12-31     0.0           200   \n",
       "4        60          0          11    101    1994-12-31     0.0           200   \n",
       "5        60          0          11    101    1994-12-31     0.0           200   \n",
       "6        60          0          11    101    1994-12-31     0.0           200   \n",
       "7        60          0          11    101    1994-12-31     0.0           200   \n",
       "8        60          0          11    101    1994-12-31     0.0           200   \n",
       "9        60          0          11    101    1994-12-31     0.0           200   \n",
       "10       60          0          11    101    1994-12-31     0.0           200   \n",
       "11       60          0          11    101    1994-12-31     0.0           200   \n",
       "12       60          0          11    101    1994-12-31     0.0           200   \n",
       "13       60          0          11    101    1994-12-31     0.0           200   \n",
       "14       60          0          11    101    1994-12-31     0.0           200   \n",
       "15       60          0          11    101    1994-12-31     0.0           200   \n",
       "16       60          0          11    101    1994-12-31     0.0           200   \n",
       "17       60          0          11    101    1994-12-31     0.0           200   \n",
       "18       60          0          11    101    1994-12-31     0.0           200   \n",
       "19       60          0          11    101    1994-12-31     0.0           200   \n",
       "\n",
       "    coop_time invoice_date  tarif_type  ...  reading_remarque  \\\n",
       "0         288   2005-10-17          11  ...                 6   \n",
       "1         288   2006-10-18          11  ...                 6   \n",
       "2         288   2006-06-23          11  ...                 6   \n",
       "3         288   2006-02-24          11  ...                 6   \n",
       "4         288   2007-02-26          11  ...                 6   \n",
       "5         288   2007-10-25          11  ...                 6   \n",
       "6         288   2007-06-27          11  ...                 6   \n",
       "7         288   2008-01-04          11  ...                 6   \n",
       "8         288   2008-07-28          11  ...                 6   \n",
       "9         288   2008-11-25          11  ...                 6   \n",
       "10        288   2009-11-24          11  ...                 6   \n",
       "11        288   2009-07-27          11  ...                 6   \n",
       "12        288   2009-01-04          11  ...                 6   \n",
       "13        288   2010-07-22          11  ...                 6   \n",
       "14        288   2010-03-29          11  ...                 6   \n",
       "15        288   2010-11-24          11  ...                 6   \n",
       "16        288   2011-11-22          11  ...                 6   \n",
       "17        288   2011-07-22          11  ...                 9   \n",
       "18        288   2011-03-30          11  ...                 6   \n",
       "19        288   2012-03-27          11  ...                 8   \n",
       "\n",
       "    counter_coefficient  months_number  counter_type  invoice_month  \\\n",
       "0                     1              4             1             10   \n",
       "1                     1              4             1             10   \n",
       "2                     1              4             1              6   \n",
       "3                     1              4             1              2   \n",
       "4                     1              4             1              2   \n",
       "5                     1              4             1             10   \n",
       "6                     1              4             1              6   \n",
       "7                     1              4             1              1   \n",
       "8                     1              4             1              7   \n",
       "9                     1              4             1             11   \n",
       "10                    1              4             1             11   \n",
       "11                    1              4             1              7   \n",
       "12                    1              4             1              1   \n",
       "13                    1              4             1              7   \n",
       "14                    1              4             1              3   \n",
       "15                    1              4             1             11   \n",
       "16                    1              4             1             11   \n",
       "17                    1              4             1              7   \n",
       "18                    1              4             1              3   \n",
       "19                    1              4             1              3   \n",
       "\n",
       "    invoice_year  is_weekday  total_consumption  mean_consumption_per_year  \\\n",
       "0           2005         0.0                124                 124.000000   \n",
       "1           2006         0.0                159                 154.000000   \n",
       "2           2006         0.0                162                 154.000000   \n",
       "3           2006         0.0                141                 154.000000   \n",
       "4           2007         0.0                182                 232.666667   \n",
       "5           2007         0.0                276                 232.666667   \n",
       "6           2007         0.0                240                 232.666667   \n",
       "7           2008         0.0                277                 207.333333   \n",
       "8           2008         0.0                171                 207.333333   \n",
       "9           2008         0.0                174                 207.333333   \n",
       "10          2009         0.0                267                 298.000000   \n",
       "11          2009         0.0                312                 298.000000   \n",
       "12          2009         1.0                315                 298.000000   \n",
       "13          2010         0.0                278                 262.666667   \n",
       "14          2010         0.0                276                 262.666667   \n",
       "15          2010         0.0                234                 262.666667   \n",
       "16          2011         0.0               1082                 988.333333   \n",
       "17          2011         0.0               1386                 988.333333   \n",
       "18          2011         0.0                497                 988.333333   \n",
       "19          2012         0.0                292                 602.000000   \n",
       "\n",
       "    historical_mean_consumption  \n",
       "0                      0.000000  \n",
       "1                    124.000000  \n",
       "2                    141.500000  \n",
       "3                    148.333333  \n",
       "4                    146.500000  \n",
       "5                    153.600000  \n",
       "6                    174.000000  \n",
       "7                    183.428571  \n",
       "8                    195.125000  \n",
       "9                    192.444444  \n",
       "10                   190.600000  \n",
       "11                   197.545455  \n",
       "12                   207.083333  \n",
       "13                   215.384615  \n",
       "14                   219.857143  \n",
       "15                   223.600000  \n",
       "16                   224.250000  \n",
       "17                   274.705882  \n",
       "18                   336.444444  \n",
       "19                   344.894737  \n",
       "\n",
       "[20 rows x 23 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline model\n",
    "- our very simple baseline model assumes every client from district 51 is fraudulent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>client_catg</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>51</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>92.391486</td>\n",
       "      <td>94.413284</td>\n",
       "      <td>79.044952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>7.608514</td>\n",
       "      <td>5.586716</td>\n",
       "      <td>20.955048</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "client_catg         11         12         51\n",
       "target                                      \n",
       "0.0          92.391486  94.413284  79.044952\n",
       "1.0           7.608514   5.586716  20.955048"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def baseline_model(X):\n",
    "    y_pred = [0 if cat != 51 else 1 for cat in X.client_catg]\n",
    "    return y_pred\n",
    "\n",
    "# in district 51 the most fraudulents appear:\n",
    "pd.crosstab(df['target'], df['client_catg'], normalize='columns')*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score: 0.21\n",
      "ROC AUC: 0.52\n"
     ]
    }
   ],
   "source": [
    "# Select the features to use for modeling\n",
    "feature_cols = ['district','client_catg', 'region_group',\n",
    "       'tarif_type', 'counter_number',\n",
    "       'counter_statue', 'counter_code', 'reading_remarque',\n",
    "       'counter_coefficient', 'months_number', 'counter_type',\n",
    "       'total_consumption', 'invoice_year', 'mean_consumption_per_year', 'historical_mean_consumption']\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[feature_cols], df['target'], test_size=0.3, random_state=42)\n",
    "y_pred = baseline_model(X_test)\n",
    "\n",
    "print('F1-score:', precision_score(y_test, y_pred).round(2))\n",
    "print('ROC AUC:', roc_auc_score(y_test, y_pred).round(2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale data\n",
    "\n",
    "# Instantiate the scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform the training data\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Transform the test data using the same scaler\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample the data to balance the classes\n",
    "\n",
    "# Separate majority and minority classes\n",
    "df_majority = df[df.target==0]\n",
    "df_minority = df[df.target==1]\n",
    "\n",
    "# Downsample majority class\n",
    "df_majority_downsampled = resample(df_majority, \n",
    "                                   replace=False,     # Sample without replacement\n",
    "                                   n_samples=len(df_minority),    # Match number in minority class\n",
    "                                   random_state=42)  # Reproducible results\n",
    "\n",
    "# Combine majority class with minority class\n",
    "df_downsampled = pd.concat([df_majority_downsampled, df_minority])\n",
    "\n",
    "# Split into X and y\n",
    "X_train_down = df_downsampled[feature_cols]\n",
    "y_train_down = df_downsampled['target']\n",
    "\n",
    "# Upsample minority class\n",
    "df_minority_upsampled = resample(df_minority, \n",
    "                                 replace=True,    # Sample with replacement\n",
    "                                 n_samples=len(df_majority),    # Match number in majority class\n",
    "                                 random_state=42)  # Reproducible results\n",
    "\n",
    "# Combine majority class with upsampled minority class\n",
    "df_upsampled = pd.concat([df_majority, df_minority_upsampled])\n",
    "\n",
    "# Split into X and y\n",
    "X_train_up = df_upsampled[feature_cols]\n",
    "y_train_up = df_upsampled['target']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A model with better performance?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost with GridSearch / Downsampling / "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Best Hyperparameters:  {'enable_categorical': True, 'learning_rate': 0.1, 'max_depth': 9, 'n_estimators': 300, 'objective': 'binary:logistic', 'seed': 42, 'tree_method': 'hist'}\n",
      "Accuracy: 0.93\n",
      "Precision: 0.89\n",
      "Recall: 0.08\n",
      "F1 Score: 0.14\n",
      "ROC AUC Score: 0.54\n"
     ]
    }
   ],
   "source": [
    "# Select the features to use for modeling\n",
    "feature_cols = ['district','client_catg', 'region_group',\n",
    "       'tarif_type', 'counter_number',\n",
    "       'counter_statue', 'counter_code', 'reading_remarque',\n",
    "       'counter_coefficient', 'months_number', 'counter_type',\n",
    "       'total_consumption', 'invoice_year', 'mean_consumption_per_year', 'historical_mean_consumption']\n",
    "\n",
    "X_train_down, X_test, y_train_down, y_test = train_test_split(df[feature_cols], df['target'], test_size=0.3, random_state=42)\n",
    "\n",
    "# Define XGBoost model with enable_categorical=True and tree_method='hist'\n",
    "xgb_model = xgb.XGBClassifier(objective='binary:logistic', seed=42, enable_categorical=True, tree_method='hist')\n",
    "\n",
    "# Define parameter grid for grid search\n",
    "param_grid = {\n",
    "    'objective': ['binary:logistic'],\n",
    "    'seed': [42],\n",
    "    'enable_categorical': [True],\n",
    "    'tree_method': ['hist'],\n",
    "    'n_estimators': [300],\n",
    "    'max_depth': [9],\n",
    "    'learning_rate': [0.1]\n",
    "}\n",
    "\n",
    "# Split data into training and test sets\n",
    "#X_train_scaled, X_test_scaled, y_train, y_test = train_test_split(X_train_scaled, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create GridSearchCV object\n",
    "clf = GridSearchCV(estimator=xgb_model, param_grid=param_grid, cv=5, n_jobs=-1, verbose=1)\n",
    "\n",
    "# Fit GridSearchCV object to training data\n",
    "clf.fit(X_train_scaled, y_train_down)\n",
    "\n",
    "# Predict on test data using best model\n",
    "y_pred = clf.predict(X_test_scaled)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "# Print best hyperparameters and evaluation metrics\n",
    "print('Best Hyperparameters: ', clf.best_params_)\n",
    "print('Accuracy: {:.2f}'.format(clf.best_score_))\n",
    "print('Precision: {:.2f}'.format(precision_score(y_test, y_pred)))\n",
    "print('Recall: {:.2f}'.format(recall_score(y_test, y_pred)))\n",
    "print('F1 Score: {:.2f}'.format(f1_score(y_test, y_pred)))\n",
    "print('ROC AUC Score: {:.2f}'.format(roc_auc_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters:  {'enable_categorical': True, 'learning_rate': 0.1, 'max_depth': 9, 'n_estimators': 300, 'objective': 'binary:logistic', 'seed': 42, 'tree_method': 'hist'}\n",
      "Accuracy: 0.93\n",
      "Precision: 0.89\n",
      "Recall: 0.08\n",
      "F1 Score: 0.14\n",
      "ROC AUC Score: 0.54\n"
     ]
    }
   ],
   "source": [
    "# Print best hyperparameters and evaluation metrics\n",
    "print('Best Hyperparameters: ', clf.best_params_)\n",
    "print('Accuracy: {:.2f}'.format(clf.best_score_))\n",
    "print('Precision: {:.2f}'.format(precision_score(y_test, y_pred)))\n",
    "print('Recall: {:.2f}'.format(recall_score(y_test, y_pred)))\n",
    "print('F1 Score: {:.2f}'.format(f1_score(y_test, y_pred)))\n",
    "print('ROC AUC Score: {:.2f}'.format(roc_auc_score(y_test, y_pred)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost with GridSearch / Upsampling / "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Best Hyperparameters:  {'enable_categorical': True, 'learning_rate': 0.1, 'max_depth': 9, 'n_estimators': 300, 'objective': 'binary:logistic', 'seed': 42, 'tree_method': 'hist'}\n",
      "Accuracy: 0.75\n",
      "Precision: 0.76\n",
      "Recall: 0.75\n",
      "F1 Score: 0.75\n",
      "ROC AUC Score: 0.75\n"
     ]
    }
   ],
   "source": [
    "# Select the features to use for modeling\n",
    "feature_cols = ['district','client_catg', 'region_group',\n",
    "       'tarif_type', 'counter_number',\n",
    "       'counter_statue', 'counter_code', 'reading_remarque',\n",
    "       'counter_coefficient', 'months_number', 'counter_type',\n",
    "       'total_consumption', 'invoice_year', 'mean_consumption_per_year', 'historical_mean_consumption']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[feature_cols], df['target'], test_size=0.3, random_state=42)\n",
    "\n",
    "# Scale data\n",
    "#from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, Normalizer\n",
    "\n",
    "# Instantiate the scaler\n",
    "#scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform the training data\n",
    "#X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Transform the test data using the same scaler\n",
    "#X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Separate majority and minority classes\n",
    "#df_majority = df[df.target==0]\n",
    "#df_minority = df[df.target==1]\n",
    "\n",
    "# Upsample minority class\n",
    "#df_minority_upsampled = resample(df_minority, \n",
    "                                 replace=True,    # Sample with replacement\n",
    "                                 n_samples=len(df_majority),    # Match number in majority class\n",
    "                                 random_state=42)  # Reproducible results\n",
    "\n",
    "# Combine majority class with upsampled minority class\n",
    "#df_upsampled = pd.concat([df_majority, df_minority_upsampled])\n",
    "\n",
    "# Split into X and y\n",
    "#X_train = df_upsampled[feature_cols]\n",
    "#y_train = df_upsampled['target']\n",
    "\n",
    "# Scale the data\n",
    "#scaler = Normalizer()\n",
    "#X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Define XGBoost model with enable_categorical=True and tree_method='hist'\n",
    "xgb_model = xgb.XGBClassifier(objective='binary:logistic', seed=42, enable_categorical=True, tree_method='hist')\n",
    "\n",
    "# Define parameter grid for grid search\n",
    "param_grid = {\n",
    "    'objective': ['binary:logistic'],\n",
    "    'seed': [42],\n",
    "    'enable_categorical': [True],\n",
    "    'tree_method': ['hist'],\n",
    "    'n_estimators': [300],\n",
    "    'max_depth': [9],\n",
    "    'learning_rate': [0.1]\n",
    "}\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train_scaled, X_test_scaled, y_train, y_test = train_test_split(X_train_scaled, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create GridSearchCV object\n",
    "clf = GridSearchCV(estimator=xgb_model, param_grid=param_grid, cv=5, n_jobs=-1, verbose=1)\n",
    "\n",
    "# Fit GridSearchCV object to training data\n",
    "clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict on test data using best model\n",
    "y_pred = clf.predict(X_test_scaled)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "# Print best hyperparameters and evaluation metrics\n",
    "print('Best Hyperparameters: ', clf.best_params_)\n",
    "print('Accuracy: {:.2f}'.format(clf.best_score_))\n",
    "print('Precision: {:.2f}'.format(precision_score(y_test, y_pred)))\n",
    "print('Recall: {:.2f}'.format(recall_score(y_test, y_pred)))\n",
    "print('F1 Score: {:.2f}'.format(f1_score(y_test, y_pred)))\n",
    "print('ROC AUC Score: {:.2f}'.format(roc_auc_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Best Hyperparameters:  {'enable_categorical': True, 'learning_rate': 0.1, 'max_depth': 9, 'n_estimators': 300, 'objective': 'binary:logistic', 'seed': 42, 'tree_method': 'hist'}\n",
      "Accuracy: 0.93\n",
      "Precision: 0.89\n",
      "Recall: 0.08\n",
      "F1 Score: 0.14\n",
      "ROC AUC Score: 0.54\n"
     ]
    }
   ],
   "source": [
    "# Select the features to use for modeling\n",
    "feature_cols = ['district','client_catg', 'region_group',\n",
    "       'tarif_type', 'counter_number',\n",
    "       'counter_statue', 'counter_code', 'reading_remarque',\n",
    "       'counter_coefficient', 'months_number', 'counter_type',\n",
    "       'total_consumption', 'invoice_year', 'mean_consumption_per_year', 'historical_mean_consumption']\n",
    "\n",
    "X_train_up, X_test, y_train_up, y_test = train_test_split(df[feature_cols], df['target'], test_size=0.3, random_state=42)\n",
    "\n",
    "# Define XGBoost model with enable_categorical=True and tree_method='hist'\n",
    "xgb_model = xgb.XGBClassifier(objective='binary:logistic', seed=42, enable_categorical=True, tree_method='hist')\n",
    "\n",
    "# Define parameter grid for grid search\n",
    "param_grid = {\n",
    "    'objective': ['binary:logistic'],\n",
    "    'seed': [42],\n",
    "    'enable_categorical': [True],\n",
    "    'tree_method': ['hist'],\n",
    "    'n_estimators': [300],\n",
    "    'max_depth': [9],\n",
    "    'learning_rate': [0.1]\n",
    "}\n",
    "\n",
    "# Split data into training and test sets\n",
    "#X_train_scaled, X_test_scaled, y_train, y_test = train_test_split(X_train_scaled, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create GridSearchCV object\n",
    "clf = GridSearchCV(estimator=xgb_model, param_grid=param_grid, cv=5, n_jobs=-1, verbose=1)\n",
    "\n",
    "# Fit GridSearchCV object to training data\n",
    "clf.fit(X_train_scaled, y_train_up)\n",
    "\n",
    "# Predict on test data using best model\n",
    "y_pred = clf.predict(X_test_scaled)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "# Print best hyperparameters and evaluation metrics\n",
    "print('Best Hyperparameters: ', clf.best_params_)\n",
    "print('Accuracy: {:.2f}'.format(clf.best_score_))\n",
    "print('Precision: {:.2f}'.format(precision_score(y_test, y_pred)))\n",
    "print('Recall: {:.2f}'.format(recall_score(y_test, y_pred)))\n",
    "print('F1 Score: {:.2f}'.format(f1_score(y_test, y_pred)))\n",
    "print('ROC AUC Score: {:.2f}'.format(roc_auc_score(y_test, y_pred)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost with RandomSearchCV / Upscaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters:  {'enable_categorical': True, 'learning_rate': 0.1, 'max_depth': 9, 'n_estimators': 300, 'objective': 'binary:logistic', 'seed': 42, 'tree_method': 'hist'}\n",
      "Accuracy: 0.93\n",
      "Precision: 0.89\n",
      "Recall: 0.11\n",
      "F1 Score: 0.20\n",
      "ROC AUC Score: 0.56\n"
     ]
    }
   ],
   "source": [
    "# Select the features to use for modeling\n",
    "feature_cols = ['district', 'client_catg', 'region_group', 'tarif_type', 'counter_number',\n",
    "                'reading_remarque', 'months_number', 'total_consumption', 'invoice_year', \n",
    "                'counter_coefficient', 'counter_code', 'counter_statue', 'counter_type']\n",
    "\n",
    "X_train_up, X_test, y_train_up, y_test = train_test_split(df[feature_cols], df['target'], test_size=0.3, random_state=42)\n",
    "\n",
    "# Define best hyperparameters\n",
    "best_params = {\n",
    "    'objective': 'binary:logistic',\n",
    "    'tree_method': 'hist',\n",
    "    'n_estimators': 400,\n",
    "    'max_depth': 11,\n",
    "    'learning_rate': 0.1,\n",
    "    'gamma': 0,\n",
    "    'subsample': 0.6,\n",
    "    'colsample_bytree': 1.0,\n",
    "    'enable_categorical': True,\n",
    "    'seed': 42\n",
    "}\n",
    "\n",
    "# Create XGBoost model with best hyperparameters\n",
    "model = xgb.XGBClassifier(**best_params)\n",
    "\n",
    "# Fit the model to the training data\n",
    "model.fit(X_train_scaled, y_train_up)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print('Best Hyperparameters: ', clf.best_params_)\n",
    "print('Accuracy: {:.2f}'.format(accuracy))\n",
    "print('Precision: {:.2f}'.format(precision))\n",
    "print('Recall: {:.2f}'.format(recall))\n",
    "print('F1 Score: {:.2f}'.format(f1))\n",
    "print('ROC AUC Score: {:.2f}'.format(roc_auc))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.92\n",
      "Precision: 0.25\n",
      "Recall: 0.00\n",
      "F1 Score: 0.00\n",
      "ROC AUC Score: 0.50\n"
     ]
    }
   ],
   "source": [
    "# Select the features to use for modeling\n",
    "feature_cols = ['district','client_catg', 'region_group',\n",
    "       'tarif_type', 'counter_number',\n",
    "       'counter_statue', 'counter_code', 'reading_remarque',\n",
    "       'counter_coefficient', 'months_number', 'counter_type',\n",
    "       'total_consumption', 'invoice_year']\n",
    "X_train_up, X_test, y_train_up, y_test = train_test_split(df[feature_cols], df['target'], test_size=0.3, random_state=42)\n",
    "\n",
    "# Fit logistic regression model on the training data\n",
    "lr = LogisticRegression(random_state=42)\n",
    "lr.fit(X_train_scaled, y_train_up)\n",
    "\n",
    "# Predict on test data using logistic regression model\n",
    "y_pred_lr = lr.predict(X_test_scaled)\n",
    "\n",
    "# Calculate evaluation metrics for logistic regression model\n",
    "accuracy_lr = accuracy_score(y_test, y_pred_lr)\n",
    "precision_lr = precision_score(y_test, y_pred_lr)\n",
    "recall_lr = recall_score(y_test, y_pred_lr)\n",
    "f1_lr = f1_score(y_test, y_pred_lr)\n",
    "roc_auc_lr = roc_auc_score(y_test, y_pred_lr)\n",
    "\n",
    "# Print best hyperparameters and evaluation metrics\n",
    "print('Accuracy: {:.2f}'.format(accuracy_lr))\n",
    "print('Precision: {:.2f}'.format(precision_lr))\n",
    "print('Recall: {:.2f}'.format(recall_lr))\n",
    "print('F1 Score: {:.2f}'.format(f1_lr))\n",
    "print('ROC AUC Score: {:.2f}'.format(roc_auc_lr))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RF with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    }
   ],
   "source": [
    "rf_model = RandomForestClassifier(n_estimators=100, max_depth=9, random_state=42)\n",
    "\n",
    "rf_model.fit(X_train_scaled, y_train_down)\n",
    "\n",
    "y_pred = rf_model.predict(X_test_scaled)\n",
    "\n",
    "# Define parameter grid for grid search\n",
    "param_grid = {\n",
    "    'random_state': [42],\n",
    "    'n_estimators': [100],\n",
    "    'max_depth': [9],\n",
    "    'verbose': [1],\n",
    "    'n_jobs': [-1],\n",
    "}\n",
    "\n",
    "# Create GridSearchCV object\n",
    "clf = GridSearchCV(estimator=rf_model, param_grid=param_grid, cv=5, n_jobs=-1, verbose=1)\n",
    "\n",
    "# Fit GridSearchCV object to training data\n",
    "clf.fit(X_train_scaled, y_train_down)\n",
    "\n",
    "# Predict on test data using best model\n",
    "y_pred = clf.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate performance on test set\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "test_precision = precision_score(y_test, y_pred)\n",
    "test_recall = recall_score(y_test, y_pred)\n",
    "test_f1 = f1_score(y_test, y_pred)\n",
    "test_roc_auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "# Print best hyperparameters and evaluation metrics on test set\n",
    "print('Best Hyperparameters: ', clf.best_params_)\n",
    "print('Train Accuracy: {:.2f}'.format(clf.best_score_))\n",
    "print('Test Accuracy: {:.2f}'.format(test_accuracy))\n",
    "print('Train Precision: {:.2f}'.format(clf.cv_results_['mean_test_score'][clf.best_index_]))\n",
    "print('Test Precision: {:.2f}'.format(test_precision))\n",
    "print('Train Recall: {:.2f}'.format(clf.cv_results_['mean_test_score'][clf.best_index_]))\n",
    "print('Test Recall: {:.2f}'.format(test_recall))\n",
    "print('Train F1 Score: {:.2f}'.format(clf.cv_results_['mean_test_score'][clf.best_index_]))\n",
    "print('Test F1 Score: {:.2f}'.format(test_f1))\n",
    "print('Train ROC AUC Score: {:.2f}'.format(clf.cv_results_['mean_test_score'][clf.best_index_]))\n",
    "print('Test ROC AUC Score: {:.2f}'.format(test_roc_auc))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest with Scikit-Optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 32\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39m-\u001b[39mtest_f1\n\u001b[1;32m     31\u001b[0m \u001b[39m# Run Bayesian optimization using the objective function and search space\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m res \u001b[39m=\u001b[39m gp_minimize(objective, space, n_calls\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m, random_state\u001b[39m=\u001b[39;49m\u001b[39m42\u001b[39;49m)\n\u001b[1;32m     34\u001b[0m \u001b[39m# Print best hyperparameters and evaluation metrics on test set\u001b[39;00m\n\u001b[1;32m     35\u001b[0m best_params \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mn_estimators\u001b[39m\u001b[39m'\u001b[39m: res\u001b[39m.\u001b[39mx[\u001b[39m0\u001b[39m], \u001b[39m'\u001b[39m\u001b[39mmax_depth\u001b[39m\u001b[39m'\u001b[39m: res\u001b[39m.\u001b[39mx[\u001b[39m1\u001b[39m], \u001b[39m'\u001b[39m\u001b[39mmin_samples_split\u001b[39m\u001b[39m'\u001b[39m: res\u001b[39m.\u001b[39mx[\u001b[39m2\u001b[39m], \u001b[39m'\u001b[39m\u001b[39mrandom_state\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m42\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mverbose\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m1\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mn_jobs\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m}\n",
      "File \u001b[0;32m~/Documents/ds-fraud-detection/.venv/lib/python3.9/site-packages/skopt/optimizer/gp.py:259\u001b[0m, in \u001b[0;36mgp_minimize\u001b[0;34m(func, dimensions, base_estimator, n_calls, n_random_starts, n_initial_points, initial_point_generator, acq_func, acq_optimizer, x0, y0, random_state, verbose, callback, n_points, n_restarts_optimizer, xi, kappa, noise, n_jobs, model_queue_size)\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[39mif\u001b[39;00m base_estimator \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    255\u001b[0m     base_estimator \u001b[39m=\u001b[39m cook_estimator(\n\u001b[1;32m    256\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mGP\u001b[39m\u001b[39m\"\u001b[39m, space\u001b[39m=\u001b[39mspace, random_state\u001b[39m=\u001b[39mrng\u001b[39m.\u001b[39mrandint(\u001b[39m0\u001b[39m, np\u001b[39m.\u001b[39miinfo(np\u001b[39m.\u001b[39mint32)\u001b[39m.\u001b[39mmax),\n\u001b[1;32m    257\u001b[0m         noise\u001b[39m=\u001b[39mnoise)\n\u001b[0;32m--> 259\u001b[0m \u001b[39mreturn\u001b[39;00m base_minimize(\n\u001b[1;32m    260\u001b[0m     func, space, base_estimator\u001b[39m=\u001b[39;49mbase_estimator,\n\u001b[1;32m    261\u001b[0m     acq_func\u001b[39m=\u001b[39;49macq_func,\n\u001b[1;32m    262\u001b[0m     xi\u001b[39m=\u001b[39;49mxi, kappa\u001b[39m=\u001b[39;49mkappa, acq_optimizer\u001b[39m=\u001b[39;49macq_optimizer, n_calls\u001b[39m=\u001b[39;49mn_calls,\n\u001b[1;32m    263\u001b[0m     n_points\u001b[39m=\u001b[39;49mn_points, n_random_starts\u001b[39m=\u001b[39;49mn_random_starts,\n\u001b[1;32m    264\u001b[0m     n_initial_points\u001b[39m=\u001b[39;49mn_initial_points,\n\u001b[1;32m    265\u001b[0m     initial_point_generator\u001b[39m=\u001b[39;49minitial_point_generator,\n\u001b[1;32m    266\u001b[0m     n_restarts_optimizer\u001b[39m=\u001b[39;49mn_restarts_optimizer,\n\u001b[1;32m    267\u001b[0m     x0\u001b[39m=\u001b[39;49mx0, y0\u001b[39m=\u001b[39;49my0, random_state\u001b[39m=\u001b[39;49mrng, verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m    268\u001b[0m     callback\u001b[39m=\u001b[39;49mcallback, n_jobs\u001b[39m=\u001b[39;49mn_jobs, model_queue_size\u001b[39m=\u001b[39;49mmodel_queue_size)\n",
      "File \u001b[0;32m~/Documents/ds-fraud-detection/.venv/lib/python3.9/site-packages/skopt/optimizer/base.py:299\u001b[0m, in \u001b[0;36mbase_minimize\u001b[0;34m(func, dimensions, base_estimator, n_calls, n_random_starts, n_initial_points, initial_point_generator, acq_func, acq_optimizer, x0, y0, random_state, verbose, callback, n_points, n_restarts_optimizer, xi, kappa, n_jobs, model_queue_size)\u001b[0m\n\u001b[1;32m    297\u001b[0m \u001b[39mfor\u001b[39;00m n \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_calls):\n\u001b[1;32m    298\u001b[0m     next_x \u001b[39m=\u001b[39m optimizer\u001b[39m.\u001b[39mask()\n\u001b[0;32m--> 299\u001b[0m     next_y \u001b[39m=\u001b[39m func(next_x)\n\u001b[1;32m    300\u001b[0m     result \u001b[39m=\u001b[39m optimizer\u001b[39m.\u001b[39mtell(next_x, next_y)\n\u001b[1;32m    301\u001b[0m     result\u001b[39m.\u001b[39mspecs \u001b[39m=\u001b[39m specs\n",
      "File \u001b[0;32m~/Documents/ds-fraud-detection/.venv/lib/python3.9/site-packages/skopt/utils.py:789\u001b[0m, in \u001b[0;36muse_named_args.<locals>.decorator.<locals>.wrapper\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    786\u001b[0m arg_dict \u001b[39m=\u001b[39m {dim\u001b[39m.\u001b[39mname: value \u001b[39mfor\u001b[39;00m dim, value \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(dimensions, x)}\n\u001b[1;32m    788\u001b[0m \u001b[39m# Call the wrapped objective function with the named arguments.\u001b[39;00m\n\u001b[0;32m--> 789\u001b[0m objective_value \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49marg_dict)\n\u001b[1;32m    791\u001b[0m \u001b[39mreturn\u001b[39;00m objective_value\n",
      "Cell \u001b[0;32mIn[43], line 22\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(n_estimators, max_depth, min_samples_split)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[39m@use_named_args\u001b[39m(space)\n\u001b[1;32m     19\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mobjective\u001b[39m(n_estimators, max_depth, min_samples_split):\n\u001b[1;32m     20\u001b[0m     \u001b[39m# Create model with specified hyperparameters\u001b[39;00m\n\u001b[1;32m     21\u001b[0m     rf_model \u001b[39m=\u001b[39m RandomForestClassifier(n_estimators\u001b[39m=\u001b[39mn_estimators, max_depth\u001b[39m=\u001b[39mmax_depth, min_samples_split\u001b[39m=\u001b[39mmin_samples_split, random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m)\n\u001b[0;32m---> 22\u001b[0m     rf_model\u001b[39m.\u001b[39;49mfit(X_train_scaled, y_train_down)\n\u001b[1;32m     24\u001b[0m     \u001b[39m# Make predictions on test data and compute evaluation metrics\u001b[39;00m\n\u001b[1;32m     25\u001b[0m     y_pred \u001b[39m=\u001b[39m rf_model\u001b[39m.\u001b[39mpredict(X_test_scaled)\n",
      "File \u001b[0;32m~/Documents/ds-fraud-detection/.venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:450\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    439\u001b[0m trees \u001b[39m=\u001b[39m [\n\u001b[1;32m    440\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_estimator(append\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, random_state\u001b[39m=\u001b[39mrandom_state)\n\u001b[1;32m    441\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_more_estimators)\n\u001b[1;32m    442\u001b[0m ]\n\u001b[1;32m    444\u001b[0m \u001b[39m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[1;32m    445\u001b[0m \u001b[39m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[1;32m    446\u001b[0m \u001b[39m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[1;32m    447\u001b[0m \u001b[39m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[1;32m    448\u001b[0m \u001b[39m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[1;32m    449\u001b[0m \u001b[39m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[0;32m--> 450\u001b[0m trees \u001b[39m=\u001b[39m Parallel(\n\u001b[1;32m    451\u001b[0m     n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs,\n\u001b[1;32m    452\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[1;32m    453\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m_joblib_parallel_args(prefer\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mthreads\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    454\u001b[0m )(\n\u001b[1;32m    455\u001b[0m     delayed(_parallel_build_trees)(\n\u001b[1;32m    456\u001b[0m         t,\n\u001b[1;32m    457\u001b[0m         \u001b[39mself\u001b[39;49m,\n\u001b[1;32m    458\u001b[0m         X,\n\u001b[1;32m    459\u001b[0m         y,\n\u001b[1;32m    460\u001b[0m         sample_weight,\n\u001b[1;32m    461\u001b[0m         i,\n\u001b[1;32m    462\u001b[0m         \u001b[39mlen\u001b[39;49m(trees),\n\u001b[1;32m    463\u001b[0m         verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[1;32m    464\u001b[0m         class_weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclass_weight,\n\u001b[1;32m    465\u001b[0m         n_samples_bootstrap\u001b[39m=\u001b[39;49mn_samples_bootstrap,\n\u001b[1;32m    466\u001b[0m     )\n\u001b[1;32m    467\u001b[0m     \u001b[39mfor\u001b[39;49;00m i, t \u001b[39min\u001b[39;49;00m \u001b[39menumerate\u001b[39;49m(trees)\n\u001b[1;32m    468\u001b[0m )\n\u001b[1;32m    470\u001b[0m \u001b[39m# Collect newly grown trees\u001b[39;00m\n\u001b[1;32m    471\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_\u001b[39m.\u001b[39mextend(trees)\n",
      "File \u001b[0;32m~/Documents/ds-fraud-detection/.venv/lib/python3.9/site-packages/joblib/parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1085\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1086\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1088\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[1;32m   1089\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[1;32m   1091\u001b[0m \u001b[39mif\u001b[39;00m pre_dispatch \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   1092\u001b[0m     \u001b[39m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[1;32m   1093\u001b[0m     \u001b[39m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[1;32m   1094\u001b[0m     \u001b[39m# consumption.\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/ds-fraud-detection/.venv/lib/python3.9/site-packages/joblib/parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    900\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 901\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[1;32m    902\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/ds-fraud-detection/.venv/lib/python3.9/site-packages/joblib/parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    818\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[0;32m--> 819\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[1;32m    820\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    821\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    822\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    823\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    824\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m~/Documents/ds-fraud-detection/.venv/lib/python3.9/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[1;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m~/Documents/ds-fraud-detection/.venv/lib/python3.9/site-packages/joblib/_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[1;32m    595\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    596\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 597\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[0;32m~/Documents/ds-fraud-detection/.venv/lib/python3.9/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/Documents/ds-fraud-detection/.venv/lib/python3.9/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/Documents/ds-fraud-detection/.venv/lib/python3.9/site-packages/sklearn/utils/fixes.py:216\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    215\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig):\n\u001b[0;32m--> 216\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Documents/ds-fraud-detection/.venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:185\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[39melif\u001b[39;00m class_weight \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbalanced_subsample\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    183\u001b[0m         curr_sample_weight \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m compute_sample_weight(\u001b[39m\"\u001b[39m\u001b[39mbalanced\u001b[39m\u001b[39m\"\u001b[39m, y, indices\u001b[39m=\u001b[39mindices)\n\u001b[0;32m--> 185\u001b[0m     tree\u001b[39m.\u001b[39;49mfit(X, y, sample_weight\u001b[39m=\u001b[39;49mcurr_sample_weight, check_input\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    186\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    187\u001b[0m     tree\u001b[39m.\u001b[39mfit(X, y, sample_weight\u001b[39m=\u001b[39msample_weight, check_input\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/Documents/ds-fraud-detection/.venv/lib/python3.9/site-packages/sklearn/tree/_classes.py:937\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    899\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\n\u001b[1;32m    900\u001b[0m     \u001b[39mself\u001b[39m, X, y, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, check_input\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, X_idx_sorted\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mdeprecated\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    901\u001b[0m ):\n\u001b[1;32m    902\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[1;32m    903\u001b[0m \n\u001b[1;32m    904\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    934\u001b[0m \u001b[39m        Fitted estimator.\u001b[39;00m\n\u001b[1;32m    935\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 937\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m    938\u001b[0m         X,\n\u001b[1;32m    939\u001b[0m         y,\n\u001b[1;32m    940\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m    941\u001b[0m         check_input\u001b[39m=\u001b[39;49mcheck_input,\n\u001b[1;32m    942\u001b[0m         X_idx_sorted\u001b[39m=\u001b[39;49mX_idx_sorted,\n\u001b[1;32m    943\u001b[0m     )\n\u001b[1;32m    944\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/Documents/ds-fraud-detection/.venv/lib/python3.9/site-packages/sklearn/tree/_classes.py:420\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    410\u001b[0m     builder \u001b[39m=\u001b[39m BestFirstTreeBuilder(\n\u001b[1;32m    411\u001b[0m         splitter,\n\u001b[1;32m    412\u001b[0m         min_samples_split,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    417\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmin_impurity_decrease,\n\u001b[1;32m    418\u001b[0m     )\n\u001b[0;32m--> 420\u001b[0m builder\u001b[39m.\u001b[39;49mbuild(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtree_, X, y, sample_weight)\n\u001b[1;32m    422\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_outputs_ \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m is_classifier(\u001b[39mself\u001b[39m):\n\u001b[1;32m    423\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_[\u001b[39m0\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Select the features to use for modeling\n",
    "feature_cols = ['district','client_catg', 'region_group',\n",
    "       'tarif_type', 'counter_number',\n",
    "       'counter_statue', 'counter_code',\n",
    "        'reading_remarque', 'counter_coefficient', \n",
    "       'months_number', 'counter_type',\n",
    "       'total_consumption', 'invoice_year', \n",
    "       'mean_consumption_per_year', 'historical_mean_consumption']\n",
    "\n",
    "X_train_down, X_test, y_train_down, y_test = train_test_split(df[feature_cols], df['target'], test_size=0.3, random_state=42)\n",
    "\n",
    "# Define hyperparameter search space\n",
    "space = [Integer(100, 400, name='n_estimators'),\n",
    "         Integer(3, 11, name='max_depth'),\n",
    "         Integer(2, 15, name='min_samples_split')]\n",
    "\n",
    "# Define objective function to minimize (in this case, negative F1 score)\n",
    "@use_named_args(space)\n",
    "def objective(n_estimators, max_depth, min_samples_split):\n",
    "    # Create model with specified hyperparameters\n",
    "    rf_model = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, min_samples_split=min_samples_split, random_state=42)\n",
    "    rf_model.fit(X_train_scaled, y_train_down)\n",
    "    \n",
    "    # Make predictions on test data and compute evaluation metrics\n",
    "    y_pred = rf_model.predict(X_test_scaled)\n",
    "    test_f1 = f1_score(y_test, y_pred, average='macro')\n",
    "    \n",
    "    # Return negative F1 score (to be minimized)\n",
    "    return -test_f1\n",
    "\n",
    "# Run Bayesian optimization using the objective function and search space\n",
    "res = gp_minimize(objective, space, n_calls=50, random_state=42)\n",
    "\n",
    "# Print best hyperparameters and evaluation metrics on test set\n",
    "best_params = {'n_estimators': res.x[0],\n",
    "                'max_depth': res.x[1],\n",
    "                'min_samples_split': res.x[2],\n",
    "                'random_state': 42,\n",
    "                'verbose': 1,\n",
    "                'n_jobs': -1}\n",
    "\n",
    "rf_model = RandomForestClassifier(**best_params)\n",
    "rf_model.fit(X_train_scaled, y_train_down)\n",
    "y_pred = rf_model.predict(X_test_scaled)\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "test_precision = precision_score(y_test, y_pred)\n",
    "test_recall = recall_score(y_test, y_pred)\n",
    "test_f1 = f1_score(y_test, y_pred)\n",
    "test_roc_auc = roc_auc_score(y_test, y_pred)\n",
    "print('Best Hyperparameters: ', best_params)\n",
    "print('Test Accuracy: {:.2f}'.format(test_accuracy))\n",
    "print('Test Precision: {:.2f}'.format(test_precision))\n",
    "print('Test Recall: {:.2f}'.format(test_recall))\n",
    "print('Test F1 Score: {:.2f}'.format(test_f1))\n",
    "print('Test ROC AUC Score: {:.2f}'.format(test_roc_auc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
